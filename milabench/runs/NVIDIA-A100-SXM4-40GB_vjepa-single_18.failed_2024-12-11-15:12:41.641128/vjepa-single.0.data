{"event": "config", "data": {"system": {"arch": "cuda", "sshkey": null, "nodes": [{"name": "local", "ip": "127.0.0.1", "sshport": 22, "user": "root", "main": true, "hostname": "cn-d001.server.mila.quebec", "local": true}], "self": {"name": "local", "ip": "127.0.0.1", "sshport": 22, "user": "root", "main": true, "hostname": "cn-d001.server.mila.quebec", "local": true}}, "dirs": {"base": "/network/scratch/o/ortizgas/data/milabench", "venv": "/network/scratch/o/ortizgas/data/milabench/venv/torch", "data": "/network/scratch/o/ortizgas/data/milabench/data", "runs": "/network/scratch/o/ortizgas/data/milabench/runs", "extra": "/network/scratch/o/ortizgas/data/milabench/extra/vjepa-single", "cache": "/network/scratch/o/ortizgas/data/milabench/cache"}, "group": "vjepa-single", "install_group": "torch", "install_variant": "cuda", "run_name": "NVIDIA-A100-SXM4-40GB_vjepa-single_18.staging", "enabled": true, "capabilities": {"nodes": 1}, "max_duration": 600, "voir": {"options": {"stop": 60, "interval": "1s"}}, "validation": {"usage": {"gpu_load_threshold": 0.5, "gpu_mem_threshold": 0.5}}, "config_base": "/home/mila/o/ortizgas/CODE/milabench/config", "config_file": "/home/mila/o/ortizgas/CODE/milabench/config/standard.yaml", "definition": "/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa", "tags": ["monogpu", "video"], "argv": {"--batch_size": 24, "--num_workers": "auto({n_worker}, 12)", "--dataset": "{milabench_data}/FakeVideo/video_metainfo.csv", "--output": "{milabench_extra}"}, "plan": {"method": "njobs", "n": 1}, "weight": 1.0, "name": "vjepa-single", "tag": ["vjepa-single", "0"], "job-number": 0, "devices": [0]}, "pipe": null}
{"event": "meta", "data": {"cpu": {"count": 256, "brand": "AMD EPYC 7742 64-Core Processor"}, "os": {"sysname": "Linux", "nodename": "cn-d001.server.mila.quebec", "release": "5.15.0-1048-nvidia", "version": "#48-Ubuntu SMP Thu Mar 21 18:19:02 UTC 2024", "machine": "x86_64"}, "accelerators": {"arch": "cuda", "gpus": {"0": {"minor_number": "1", "device": 0, "product": "NVIDIA A100-SXM4-40GB", "memory": {"used": 620.875, "total": 40960.0}, "utilization": {"compute": 0.0, "memory": 0}, "temperature": 25.0, "power": 54.52, "selection_variable": "CUDA_VISIBLE_DEVICES"}}}, "date": 1733965720.877973, "milabench": {"tag": "v1.0.0_RC1-13-g7a90b16", "commit": "7a90b1691650232ecd63abded0b7be84bb294c05", "date": "2024-11-08 11:28:56 -0500"}, "pytorch": {"torch": "2.4.0+cu121", "compiler": "GCC 9.3", "cpp": "C++ Version: 201703", "intel": "Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications", "mkl": "OpenMP 201511 (a.k.a. OpenMP 4.5)", "openmp": "OpenMP 201511 (a.k.a. OpenMP 4.5)", "lapack": "LAPACK is enabled (usually provided by MKL)", "nnpack": "NNPACK is enabled", "cpu": "CPU capability usage: AVX2", "build_settings": {"BLAS_INFO": "mkl", "BUILD_TYPE": "Release", "CUDA_VERSION": "12.1", "CUDNN_VERSION": "9.1.0", "CXX_COMPILER": "/opt/rh/devtoolset-9/root/usr/bin/c++", "CXX_FLAGS": "-D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow", "LAPACK_INFO": "mkl", "PERF_WITH_AVX": "1", "PERF_WITH_AVX2": "1", "PERF_WITH_AVX512": "1", "TORCH_VERSION": "2.4.0", "USE_CUDA": "ON", "USE_CUDNN": "ON", "USE_CUSPARSELT": "1", "USE_EXCEPTION_PTR": "1", "USE_GFLAGS": "OFF", "USE_GLOG": "OFF", "USE_GLOO": "ON", "USE_MKL": "ON", "USE_MKLDNN": "ON", "USE_MPI": "OFF", "USE_NCCL": "1", "USE_NNPACK": "ON", "USE_OPENMP": "ON", "USE_ROCM": "OFF", "USE_ROCM_KERNEL_ASSERT": "OFF"}}}, "pipe": null}
{"event": "start", "data": {"command": ["/network/scratch/o/ortizgas/data/milabench/venv/torch/bin/voir", "--config", "/network/scratch/o/ortizgas/data/milabench/extra/vjepa-single/voirconf-vjepa-single.0-0efae956f1553a76c1e03985181900f5.json", "/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py", "--batch_size", "18", "--num_workers", "12", "--dataset", "/network/scratch/o/ortizgas/data/milabench/data/FakeVideo/video_metainfo.csv", "--output", "/network/scratch/o/ortizgas/data/milabench/extra/vjepa-single"], "time": 1733947720.9783528}, "pipe": null}
{"event": "phase", "data": {"name": "init"}, "pipe": "data"}
{"event": "phase", "data": {"name": "parse_args"}, "pipe": "data"}
{"event": "phase", "data": {"name": "load_script"}, "pipe": "data"}
{"event": "phase", "data": {"name": "run_script"}, "pipe": "data"}
{"event": "line", "data": "INFO:__main__:loaded params...\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:which_dtype='bfloat16'\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:Initialized (rank/world-size) 0/1\n", "pipe": "stdout"}
{"event": "data", "data": {"task": "main", "time": 1733947738.8159587, "gpudata": {"0": {"memory": [624.125, 40960.0], "load": 0.0, "temperature": 24.0, "power": 54.52}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1733947738.8159587, "process": {"pid": 2859232, "load": 0.0, "num": 80, "read_bytes": 304047288.0, "write_bytes": 4186.0, "read_chars": 36793243.0, "write_chars": 677.0, "memory": [3153960960.0, 1081172426752]}}, "pipe": "data"}
{"event": "line", "data": "INFO:root:MultiMaskWrapper(\n", "pipe": "stdout"}
{"event": "line", "data": "  (backbone): VisionTransformer(\n", "pipe": "stdout"}
{"event": "line", "data": "    (patch_embed): PatchEmbed3D(\n", "pipe": "stdout"}
{"event": "line", "data": "      (proj): Conv3d(3, 1280, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n", "pipe": "stdout"}
{"event": "line", "data": "    )\n", "pipe": "stdout"}
{"event": "line", "data": "    (blocks): ModuleList(\n", "pipe": "stdout"}
{"event": "line", "data": "      (0-31): 32 x Block(\n", "pipe": "stdout"}
{"event": "line", "data": "        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n", "pipe": "stdout"}
{"event": "line", "data": "        (attn): Attention(\n", "pipe": "stdout"}
{"event": "line", "data": "          (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (attn_drop): Dropout(p=0.0, inplace=False)\n", "pipe": "stdout"}
{"event": "line", "data": "          (proj): Linear(in_features=1280, out_features=1280, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (proj_drop): Dropout(p=0.0, inplace=False)\n", "pipe": "stdout"}
{"event": "line", "data": "        )\n", "pipe": "stdout"}
{"event": "line", "data": "        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n", "pipe": "stdout"}
{"event": "line", "data": "        (mlp): MLP(\n", "pipe": "stdout"}
{"event": "line", "data": "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (act): GELU(approximate='none')\n", "pipe": "stdout"}
{"event": "line", "data": "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (drop): Dropout(p=0.0, inplace=False)\n", "pipe": "stdout"}
{"event": "line", "data": "        )\n", "pipe": "stdout"}
{"event": "line", "data": "      )\n", "pipe": "stdout"}
{"event": "line", "data": "    )\n", "pipe": "stdout"}
{"event": "line", "data": "    (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n", "pipe": "stdout"}
{"event": "line", "data": "  )\n", "pipe": "stdout"}
{"event": "line", "data": ")\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:root:PredictorMultiMaskWrapper(\n", "pipe": "stdout"}
{"event": "line", "data": "  (backbone): VisionTransformerPredictor(\n", "pipe": "stdout"}
{"event": "line", "data": "    (predictor_embed): Linear(in_features=1280, out_features=384, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "    (mask_tokens): ParameterList(\n", "pipe": "stdout"}
{"event": "line", "data": "        (0): Parameter containing: [torch.float32 of size 1x1x384 (cuda:0)]\n", "pipe": "stdout"}
{"event": "line", "data": "        (1): Parameter containing: [torch.float32 of size 1x1x384 (cuda:0)]\n", "pipe": "stdout"}
{"event": "line", "data": "    )\n", "pipe": "stdout"}
{"event": "line", "data": "    (predictor_blocks): ModuleList(\n", "pipe": "stdout"}
{"event": "line", "data": "      (0-11): 12 x Block(\n", "pipe": "stdout"}
{"event": "line", "data": "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n", "pipe": "stdout"}
{"event": "line", "data": "        (attn): Attention(\n", "pipe": "stdout"}
{"event": "line", "data": "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (attn_drop): Dropout(p=0.0, inplace=False)\n", "pipe": "stdout"}
{"event": "line", "data": "          (proj): Linear(in_features=384, out_features=384, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (proj_drop): Dropout(p=0.0, inplace=False)\n", "pipe": "stdout"}
{"event": "line", "data": "        )\n", "pipe": "stdout"}
{"event": "line", "data": "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n", "pipe": "stdout"}
{"event": "line", "data": "        (mlp): MLP(\n", "pipe": "stdout"}
{"event": "line", "data": "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (act): GELU(approximate='none')\n", "pipe": "stdout"}
{"event": "line", "data": "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (drop): Dropout(p=0.0, inplace=False)\n", "pipe": "stdout"}
{"event": "line", "data": "        )\n", "pipe": "stdout"}
{"event": "line", "data": "      )\n", "pipe": "stdout"}
{"event": "line", "data": "    )\n", "pipe": "stdout"}
{"event": "line", "data": "    (predictor_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n", "pipe": "stdout"}
{"event": "line", "data": "    (predictor_proj): Linear(in_features=384, out_features=1280, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "  )\n", "pipe": "stdout"}
{"event": "line", "data": ")\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:root:Encoder number of parameters: 631648000\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:root:Predictor number of parameters: 22279808\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:Initializing basic multi-block mask\n", "pipe": "stdout"}
{"event": "line", "data": "Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (64)", "pipe": "stderr"}
{"event": "line", "data": "INFO:root:VideoDataset dataset created\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:root:VideoDataset unsupervised data loader created\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:iterations per epoch/dataest length: 300/55\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:root:Using AdamW\n", "pipe": "stdout"}
{"event": "line", "data": "/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/jepa/app/vjepa/utils.py:209: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n", "pipe": "stderr"}
{"event": "line", "data": "  scaler = torch.cuda.amp.GradScaler() if mixed_precision else None\n", "pipe": "stderr"}
{"event": "line", "data": "INFO:__main__:Initializing loader...\n", "pipe": "stdout"}
{"event": "data", "data": {"progress": [0, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "line", "data": "Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (64)", "pipe": "stderr"}
{"event": "data", "data": {"task": "main", "time": 1733947749.8876271, "gpudata": {"0": {"memory": [6223.625, 40960.0], "load": 0.0, "temperature": 25.0, "power": 63.032}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1733947749.8876271, "process": {"pid": 2859232, "load": 0.226171875, "num": 84, "read_bytes": 931727582.0, "write_bytes": 12378.0, "read_chars": 100931364.0, "write_chars": 82709.0, "memory": [1311334400.0, 1081172426752]}}, "pipe": "data"}
{"event": "line", "data": "Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (64)", "pipe": "stderr"}
{"event": "data", "data": {"task": "main", "time": 1733947763.963959, "gpudata": {"0": {"memory": [6223.625, 40960.0], "load": 0.0, "temperature": 25.0, "power": 63.032}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1733947763.963959, "process": {"pid": 2859232, "load": 0.230078125, "num": 84, "read_bytes": 1304062611.0, "write_bytes": 16474.0, "read_chars": 146438871.0, "write_chars": 160588.0, "memory": [1639874560.0, 1081172426752]}}, "pipe": "data"}
{"event": "line", "data": "Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (64)", "pipe": "stderr"}
{"event": "line", "data": "Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (64)", "pipe": "stderr"}
{"event": "line", "data": "Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (64)", "pipe": "stderr"}
{"event": "data", "data": {"task": "main", "time": 1733947779.040354, "gpudata": {"0": {"memory": [6223.625, 40960.0], "load": 0.0, "temperature": 25.0, "power": 63.032}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1733947779.040354, "process": {"pid": 2859232, "load": 0.0, "num": 81, "read_bytes": 2171242777.0, "write_bytes": 24666.0, "read_chars": 250254400.0, "write_chars": 315584.0, "memory": [2204221440.0, 1081172426752]}}, "pipe": "data"}
{"event": "line", "data": "Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (64)", "pipe": "stderr"}
{"event": "data", "data": {"task": "main", "time": 1733947796.120342, "gpudata": {"0": {"memory": [6223.625, 40960.0], "load": 0.0, "temperature": 25.0, "power": 63.032}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1733947796.120342, "process": {"pid": 2859232, "load": 0.0, "num": 86, "read_bytes": 2739113857.0, "write_bytes": 32858.0, "read_chars": 309919803.0, "write_chars": 470392.0, "memory": [2881916928.0, 1081172426752]}}, "pipe": "data"}
{"event": "line", "data": "Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (64)", "pipe": "stderr"}
{"event": "line", "data": "Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (64)", "pipe": "stderr"}
{"event": "data", "data": {"task": "main", "time": 1733947815.2015662, "gpudata": {"0": {"memory": [6223.625, 40960.0], "load": 0.0, "temperature": 25.0, "power": 63.032}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1733947815.2015662, "process": {"pid": 2859232, "load": 0.0, "num": 84, "read_bytes": 3244647314.0, "write_bytes": 36954.0, "read_chars": 373744589.0, "write_chars": 548319.0, "memory": [3139362816.0, 1081172426752]}}, "pipe": "data"}
{"event": "line", "data": "Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (64)", "pipe": "stderr"}
{"event": "line", "data": "Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (64)", "pipe": "stderr"}
{"event": "data", "data": {"task": "main", "time": 1733947835.2848022, "gpudata": {"0": {"memory": [6223.625, 40960.0], "load": 0.0, "temperature": 25.0, "power": 63.032}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1733947835.2848022, "process": {"pid": 2859232, "load": 0.0, "num": 85, "read_bytes": 3965502776.0, "write_bytes": 45146.0, "read_chars": 455890899.0, "write_chars": 703217.0, "memory": [3737501696.0, 1081172426752]}}, "pipe": "data"}
{"event": "line", "data": "Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (64)", "pipe": "stderr"}
{"event": "line", "data": "INFO:__main__:Epoch 1\n", "pipe": "stdout"}
{"event": "line", "data": "Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (64)", "pipe": "stderr"}
{"event": "line", "data": "/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py:463: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n", "pipe": "stderr"}
{"event": "line", "data": "  with acc.amp.autocast(dtype=dtype, enabled=mixed_precision):\n", "pipe": "stderr"}
{"event": "line", "data": "/home/mila/o/ortizgas/env/cp310/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n", "pipe": "stderr"}
{"event": "line", "data": "  self.gen = func(*args, **kwds)\n", "pipe": "stderr"}
{"event": "line", "data": "INFO:__main__:[1,     0] loss: 0.848 | p0.848 r0.832 | input_var: 0.359 0.273 | masks: [320.0, 96.0] [wd: 4.00e-02] [lr: 2.00e-04] [mem: 2.52e+04] [gpu: 4669.6 ms][wall: 9708.6 ms]\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,     0] first moment: 4.74e-06 [9.83e-08 6.75e-05] second moment: 2.47e-11 [6.88e-15 7.46e-10]\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,     0] enc_grad_stats: f/l[2.66e-02 5.82e-03] mn/mx(5.82e-03, 2.97e-02) 0.00e+00\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,     0] pred_grad_stats: f/l[9.76e-02 6.13e-02] mn/mx(8.07e-03, 3.80e-01) 0.00e+00\n", "pipe": "stdout"}
{"event": "data", "data": {"progress": [1, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [2, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [3, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [4, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [5, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [6, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [7, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [8, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [9, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1733947857.3716006, "gpudata": {"0": {"memory": [6223.625, 40960.0], "load": 0.0, "temperature": 25.0, "power": 63.032}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1733947857.3716006, "process": {"pid": 2859232, "load": 0.00390625, "num": 80, "read_bytes": 25372275344.0, "write_bytes": 53338.0, "read_chars": 21198460141.0, "write_chars": 965589.0, "memory": [8539197440.0, 1081172426752]}}, "pipe": "data"}
{"event": "data", "data": {"progress": [10, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "line", "data": "INFO:__main__:[1,    10] loss: 0.610 | p0.610 r0.947 | input_var: 0.360 0.330 | masks: [372.4, 94.5] [wd: 4.00e-02] [lr: 2.00e-04] [mem: 3.46e+04] [gpu: 1312.0 ms][wall: 1777.8 ms]\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,    10] first moment: 3.60e-06 [3.56e-08 2.52e-04] second moment: 4.43e-11 [6.96e-15 2.95e-09]\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,    10] enc_grad_stats: f/l[2.64e-05 2.06e-05] mn/mx(1.61e-05, 4.88e-05) 0.00e+00\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,    10] pred_grad_stats: f/l[4.11e-03 4.31e-03] mn/mx(3.28e-04, 3.45e-01) 0.00e+00\n", "pipe": "stdout"}
{"event": "data", "data": {"progress": [11, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [12, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [13, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [14, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [15, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [16, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [17, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [18, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [19, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [20, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "line", "data": "INFO:__main__:[1,    20] loss: 0.514 | p0.514 r0.962 | input_var: 0.360 0.333 | masks: [377.9, 107.4] [wd: 4.00e-02] [lr: 2.01e-04] [mem: 3.49e+04] [gpu: 1137.7 ms][wall: 1386.3 ms]\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,    20] first moment: 2.87e-06 [1.25e-08 2.77e-04] second moment: 5.88e-11 [6.89e-15 5.25e-09]\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,    20] enc_grad_stats: f/l[2.63e-05 1.26e-05] mn/mx(1.23e-05, 4.93e-05) 0.00e+00\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,    20] pred_grad_stats: f/l[2.40e-03 2.73e-03] mn/mx(1.98e-04, 3.27e-01) 0.00e+00\n", "pipe": "stdout"}
{"event": "data", "data": {"progress": [21, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [22, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [23, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [24, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [25, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [26, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [27, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [28, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [29, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [30, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "line", "data": "INFO:__main__:[1,    30] loss: 0.433 | p0.433 r0.968 | input_var: 0.360 0.332 | masks: [380.4, 107.6] [wd: 4.00e-02] [lr: 2.01e-04] [mem: 3.71e+04] [gpu: 1054.0 ms][wall: 1225.1 ms]\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,    30] first moment: 2.14e-06 [4.47e-09 2.48e-04] second moment: 6.85e-11 [6.82e-15 6.80e-09]\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,    30] enc_grad_stats: f/l[1.48e-05 7.88e-06] mn/mx(7.65e-06, 2.83e-05) 0.00e+00\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,    30] pred_grad_stats: f/l[1.56e-03 1.89e-03] mn/mx(1.37e-04, 2.42e-01) 0.00e+00\n", "pipe": "stdout"}
{"event": "data", "data": {"progress": [31, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [32, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [33, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [34, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1733947881.4636166, "gpudata": {"0": {"memory": [38859.625, 40960.0], "load": 1.0, "temperature": 45.0, "power": 372.628}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1733947881.4636166, "process": {"pid": 2859232, "load": 0.0, "num": 81, "read_bytes": 46276479809.0, "write_bytes": 54292.0, "read_chars": 41982247075.0, "write_chars": 1031220.0, "memory": [15597752320.0, 1081172426752]}}, "pipe": "data"}
{"event": "data", "data": {"progress": [35, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [36, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [37, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "error", "data": {"type": "OutOfMemoryError", "message": "CUDA out of memory. Tried to allocate 450.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 298.38 MiB is free. Including non-PyTorch memory, this process has 39.08 GiB memory in use. Of the allocated memory 34.97 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [624.125, 40960.0], "load": 0.0, "temperature": 24.0, "power": 54.52}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [624.125, 40960.0], "load": 0.0, "temperature": 24.0, "power": 54.52}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [624.125, 40960.0], "load": 0.0, "temperature": 24.0, "power": 54.52}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [6223.6875, 40960.0], "load": 0.0, "temperature": 25.0, "power": 63.032}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [6223.625, 40960.0], "load": 0.0, "temperature": 25.0, "power": 63.032}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [6223.625, 40960.0], "load": 0.0, "temperature": 25.0, "power": 63.032}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [6223.625, 40960.0], "load": 0.0, "temperature": 25.0, "power": 63.032}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [6223.625, 40960.0], "load": 0.0, "temperature": 25.0, "power": 63.032}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [6223.625, 40960.0], "load": 0.0, "temperature": 25.0, "power": 63.032}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [6223.625, 40960.0], "load": 0.0, "temperature": 25.0, "power": 63.032}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [6223.625, 40960.0], "load": 0.0, "temperature": 25.0, "power": 63.032}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [6223.625, 40960.0], "load": 0.0, "temperature": 25.0, "power": 63.032}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [6223.625, 40960.0], "load": 0.0, "temperature": 25.0, "power": 63.032}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [6223.625, 40960.0], "load": 0.0, "temperature": 25.0, "power": 63.032}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [20095.625, 40960.0], "load": 0.98, "temperature": 31.0, "power": 268.996}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [38859.625, 40960.0], "load": 0.62, "temperature": 45.0, "power": 404.871}}}, "pipe": "data"}
{"event": "phase", "data": {"name": "finalize"}, "pipe": "data"}
{"event": "line", "data": "[rank0]: Traceback (most recent call last):\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/bin/voir\", line 8, in <module>\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     sys.exit(main())\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/cli.py\", line 128, in main\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     ov(sys.argv[1:] if argv is None else argv)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/phase.py\", line 331, in __call__\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     self._run(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/overseer.py\", line 242, in _run\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     set_value(func())\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/scriptutils.py\", line 37, in <lambda>\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     return lambda: exec(mainsection, glb, glb)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py\", line 656, in <module>\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     main()\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py\", line 645, in main\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     _main(params)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py\", line 509, in _main\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     (loss, loss_jepa, loss_reg, _new_lr, _new_wd, grad_stats, grad_stats_pred, optim_stats,), gpu_etime_ms = gpu_timer(train_step)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/jepa/src/utils/logging.py\", line 24, in gpu_timer\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     result = closure()\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py\", line 467, in train_step\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     pstd_z = reg_fn(z)  # predictor variance across patches\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py\", line 459, in reg_fn\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     return sum([torch.sqrt(zi.var(dim=1) + 0.0001) for zi in z]) / len(z)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py\", line 459, in <listcomp>\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     return sum([torch.sqrt(zi.var(dim=1) + 0.0001) for zi in z]) / len(z)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 450.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 298.38 MiB is free. Including non-PyTorch memory, this process has 39.08 GiB memory in use. Of the allocated memory 34.97 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n", "pipe": "stderr"}
{"event": "end", "data": {"command": ["/network/scratch/o/ortizgas/data/milabench/venv/torch/bin/voir", "--config", "/network/scratch/o/ortizgas/data/milabench/extra/vjepa-single/voirconf-vjepa-single.0-0efae956f1553a76c1e03985181900f5.json", "/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py", "--batch_size", "18", "--num_workers", "12", "--dataset", "/network/scratch/o/ortizgas/data/milabench/data/FakeVideo/video_metainfo.csv", "--output", "/network/scratch/o/ortizgas/data/milabench/extra/vjepa-single"], "time": 1733947960.8720968, "return_code": 1}, "pipe": null}

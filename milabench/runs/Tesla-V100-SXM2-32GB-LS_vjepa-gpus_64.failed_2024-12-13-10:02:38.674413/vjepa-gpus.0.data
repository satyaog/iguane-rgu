{"event": "config", "data": {"system": {"arch": "cuda", "sshkey": null, "nodes": [{"name": "local", "ip": "127.0.0.1", "sshport": 22, "user": "root", "main": true, "hostname": "cn-e002.server.mila.quebec", "local": true}], "self": {"name": "local", "ip": "127.0.0.1", "sshport": 22, "user": "root", "main": true, "hostname": "cn-e002.server.mila.quebec", "local": true}}, "dirs": {"base": "/network/scratch/o/ortizgas/data/milabench", "venv": "/network/scratch/o/ortizgas/data/milabench/venv/torch", "data": "/network/scratch/o/ortizgas/data/milabench/data", "runs": "/network/scratch/o/ortizgas/data/milabench/runs", "extra": "/network/scratch/o/ortizgas/data/milabench/extra/vjepa-gpus", "cache": "/network/scratch/o/ortizgas/data/milabench/cache"}, "group": "vjepa-gpus", "install_group": "torch", "install_variant": "cuda", "run_name": "Tesla-V100-SXM2-32GB-LS_vjepa-gpus_64.staging", "enabled": true, "capabilities": {"nodes": 1}, "max_duration": 600, "voir": {"options": {"stop": 60, "interval": "1s"}}, "validation": {"usage": {"gpu_load_threshold": 0.5, "gpu_mem_threshold": 0.5}}, "config_base": "/home/mila/o/ortizgas/CODE/milabench/config", "config_file": "/home/mila/o/ortizgas/CODE/milabench/config/standard.yaml", "definition": "/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa", "tags": ["multigpu", "video"], "argv": {"--batch_size": 24, "--num_workers": "auto({n_worker}, 12)", "--dataset": "{milabench_data}/FakeVideo/video_metainfo.csv", "--output": "{milabench_extra}"}, "plan": {"method": "njobs", "n": 1}, "weight": 1.0, "name": "vjepa-gpus", "tag": ["vjepa-gpus", "0"], "job-number": 0, "devices": [0, 1, 2, 3]}, "pipe": null}
{"event": "meta", "data": {"cpu": {"count": 40, "brand": "Intel(R) Xeon(R) CPU E5-2698 v4 @ 2.20GHz"}, "os": {"sysname": "Linux", "nodename": "cn-e002.server.mila.quebec", "release": "5.15.0-1048-nvidia", "version": "#48-Ubuntu SMP Thu Mar 21 18:19:02 UTC 2024", "machine": "x86_64"}, "accelerators": {"arch": "cuda", "gpus": {"0": {"minor_number": "0", "device": 0, "product": "Tesla V100-SXM2-32GB-LS", "memory": {"used": 267.0, "total": 32768.0}, "utilization": {"compute": 0.0, "memory": 0}, "temperature": 38.0, "power": 45.451, "selection_variable": "CUDA_VISIBLE_DEVICES"}, "1": {"minor_number": "1", "device": 1, "product": "Tesla V100-SXM2-32GB-LS", "memory": {"used": 267.0, "total": 32768.0}, "utilization": {"compute": 0.0, "memory": 0}, "temperature": 35.0, "power": 44.939, "selection_variable": "CUDA_VISIBLE_DEVICES"}, "2": {"minor_number": "5", "device": 2, "product": "Tesla V100-SXM2-32GB-LS", "memory": {"used": 267.0, "total": 32768.0}, "utilization": {"compute": 0.0, "memory": 0}, "temperature": 33.0, "power": 41.593, "selection_variable": "CUDA_VISIBLE_DEVICES"}, "3": {"minor_number": "6", "device": 3, "product": "Tesla V100-SXM2-32GB-LS", "memory": {"used": 267.0, "total": 32768.0}, "utilization": {"compute": 0.0, "memory": 0}, "temperature": 37.0, "power": 44.004, "selection_variable": "CUDA_VISIBLE_DEVICES"}}}, "date": 1734119957.25622, "milabench": {"tag": "v1.0.0_RC1-13-g7a90b16", "commit": "7a90b1691650232ecd63abded0b7be84bb294c05", "date": "2024-11-08 11:28:56 -0500"}, "pytorch": {"torch": "2.4.0+cu121", "compiler": "GCC 9.3", "cpp": "C++ Version: 201703", "intel": "Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications", "mkl": "OpenMP 201511 (a.k.a. OpenMP 4.5)", "openmp": "OpenMP 201511 (a.k.a. OpenMP 4.5)", "lapack": "LAPACK is enabled (usually provided by MKL)", "nnpack": "NNPACK is enabled", "cpu": "CPU capability usage: AVX2", "build_settings": {"BLAS_INFO": "mkl", "BUILD_TYPE": "Release", "CUDA_VERSION": "12.1", "CUDNN_VERSION": "9.1.0", "CXX_COMPILER": "/opt/rh/devtoolset-9/root/usr/bin/c++", "CXX_FLAGS": "-D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow", "LAPACK_INFO": "mkl", "PERF_WITH_AVX": "1", "PERF_WITH_AVX2": "1", "PERF_WITH_AVX512": "1", "TORCH_VERSION": "2.4.0", "USE_CUDA": "ON", "USE_CUDNN": "ON", "USE_CUSPARSELT": "1", "USE_EXCEPTION_PTR": "1", "USE_GFLAGS": "OFF", "USE_GLOG": "OFF", "USE_GLOO": "ON", "USE_MKL": "ON", "USE_MKLDNN": "ON", "USE_MPI": "OFF", "USE_NCCL": "1", "USE_NNPACK": "ON", "USE_OPENMP": "ON", "USE_ROCM": "OFF", "USE_ROCM_KERNEL_ASSERT": "OFF"}}}, "pipe": null}
{"event": "start", "data": {"command": ["/network/scratch/o/ortizgas/data/milabench/venv/torch/bin/benchrun", "--nnodes=1", "--rdzv-backend=static", "--rdzv-endpoint=cn-e002.server.mila.quebec:29400", "--master-addr=cn-e002.server.mila.quebec", "--master-port=29400", "--local-ranks-filter=0", "--nproc-per-node=4", "--", "/network/scratch/o/ortizgas/data/milabench/venv/torch/bin/voir", "--config", "/network/scratch/o/ortizgas/data/milabench/extra/vjepa-gpus/voirconf-vjepa-gpus.0-0efae956f1553a76c1e03985181900f5.json", "/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py", "--batch_size", "64", "--num_workers", "12", "--dataset", "/network/scratch/o/ortizgas/data/milabench/data/FakeVideo/video_metainfo.csv", "--output", "/network/scratch/o/ortizgas/data/milabench/extra/vjepa-gpus"], "time": 1734101957.3602872}, "pipe": null}
{"event": "phase", "data": {"name": "init"}, "pipe": "data"}
{"event": "phase", "data": {"name": "parse_args"}, "pipe": "data"}
{"event": "phase", "data": {"name": "load_script"}, "pipe": "data"}
{"event": "phase", "data": {"name": "run_script"}, "pipe": "data"}
{"event": "line", "data": "INFO:__main__:loaded params...\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:which_dtype='bfloat16'\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:Initialized (rank/world-size) 0/4\n", "pipe": "stdout"}
{"event": "data", "data": {"task": "main", "time": 1734101981.8325832, "gpudata": {"0": {"memory": [270.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 44.969}, "1": {"memory": [576.625, 32768.0], "load": 0.0, "temperature": 36.0, "power": 50.722}, "2": {"memory": [576.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 47.831}, "3": {"memory": [576.625, 32768.0], "load": 0.0, "temperature": 37.0, "power": 49.791}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734101981.8325832, "iodata": {"read_count": 0, "write_count": 7, "read_bytes": 0, "read_time": 0, "write_time": 3, "busy_time": 8}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734101981.8325832, "netdata": {"bytes_sent": 24673876938714, "bytes_recv": 25094367824437, "packets_sent": 2801989688, "packets_recv": 3105294264, "errin": 0, "errout": 0, "dropin": 0, "dropout": 0}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734101981.8325832, "cpudata": {"memory": [41328250880, 540098572288], "load": 0.0}}, "pipe": "data"}
{"event": "line", "data": "INFO:root:MultiMaskWrapper(\n", "pipe": "stdout"}
{"event": "line", "data": "  (backbone): VisionTransformer(\n", "pipe": "stdout"}
{"event": "line", "data": "    (patch_embed): PatchEmbed3D(\n", "pipe": "stdout"}
{"event": "line", "data": "      (proj): Conv3d(3, 1280, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n", "pipe": "stdout"}
{"event": "line", "data": "    )\n", "pipe": "stdout"}
{"event": "line", "data": "    (blocks): ModuleList(\n", "pipe": "stdout"}
{"event": "line", "data": "      (0-31): 32 x Block(\n", "pipe": "stdout"}
{"event": "line", "data": "        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n", "pipe": "stdout"}
{"event": "line", "data": "        (attn): Attention(\n", "pipe": "stdout"}
{"event": "line", "data": "          (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (attn_drop): Dropout(p=0.0, inplace=False)\n", "pipe": "stdout"}
{"event": "line", "data": "          (proj): Linear(in_features=1280, out_features=1280, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (proj_drop): Dropout(p=0.0, inplace=False)\n", "pipe": "stdout"}
{"event": "line", "data": "        )\n", "pipe": "stdout"}
{"event": "line", "data": "        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n", "pipe": "stdout"}
{"event": "line", "data": "        (mlp): MLP(\n", "pipe": "stdout"}
{"event": "line", "data": "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (act): GELU(approximate='none')\n", "pipe": "stdout"}
{"event": "line", "data": "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (drop): Dropout(p=0.0, inplace=False)\n", "pipe": "stdout"}
{"event": "line", "data": "        )\n", "pipe": "stdout"}
{"event": "line", "data": "      )\n", "pipe": "stdout"}
{"event": "line", "data": "    )\n", "pipe": "stdout"}
{"event": "line", "data": "    (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n", "pipe": "stdout"}
{"event": "line", "data": "  )\n", "pipe": "stdout"}
{"event": "line", "data": ")\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:root:PredictorMultiMaskWrapper(\n", "pipe": "stdout"}
{"event": "line", "data": "  (backbone): VisionTransformerPredictor(\n", "pipe": "stdout"}
{"event": "line", "data": "    (predictor_embed): Linear(in_features=1280, out_features=384, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "    (mask_tokens): ParameterList(\n", "pipe": "stdout"}
{"event": "line", "data": "        (0): Parameter containing: [torch.float32 of size 1x1x384 (cuda:0)]\n", "pipe": "stdout"}
{"event": "line", "data": "        (1): Parameter containing: [torch.float32 of size 1x1x384 (cuda:0)]\n", "pipe": "stdout"}
{"event": "line", "data": "    )\n", "pipe": "stdout"}
{"event": "line", "data": "    (predictor_blocks): ModuleList(\n", "pipe": "stdout"}
{"event": "line", "data": "      (0-11): 12 x Block(\n", "pipe": "stdout"}
{"event": "line", "data": "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n", "pipe": "stdout"}
{"event": "line", "data": "        (attn): Attention(\n", "pipe": "stdout"}
{"event": "line", "data": "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (attn_drop): Dropout(p=0.0, inplace=False)\n", "pipe": "stdout"}
{"event": "line", "data": "          (proj): Linear(in_features=384, out_features=384, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (proj_drop): Dropout(p=0.0, inplace=False)\n", "pipe": "stdout"}
{"event": "line", "data": "        )\n", "pipe": "stdout"}
{"event": "line", "data": "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n", "pipe": "stdout"}
{"event": "line", "data": "        (mlp): MLP(\n", "pipe": "stdout"}
{"event": "line", "data": "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (act): GELU(approximate='none')\n", "pipe": "stdout"}
{"event": "line", "data": "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (drop): Dropout(p=0.0, inplace=False)\n", "pipe": "stdout"}
{"event": "line", "data": "        )\n", "pipe": "stdout"}
{"event": "line", "data": "      )\n", "pipe": "stdout"}
{"event": "line", "data": "    )\n", "pipe": "stdout"}
{"event": "line", "data": "    (predictor_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n", "pipe": "stdout"}
{"event": "line", "data": "    (predictor_proj): Linear(in_features=384, out_features=1280, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "  )\n", "pipe": "stdout"}
{"event": "line", "data": ")\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:root:Encoder number of parameters: 631648000\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:root:Predictor number of parameters: 22279808\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:Initializing basic multi-block mask\n", "pipe": "stdout"}
{"event": "data", "data": {"task": "main", "time": 1734101991.8541062, "gpudata": {"0": {"memory": [5756.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.722}, "1": {"memory": [5756.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.722}, "2": {"memory": [5756.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 47.831}, "3": {"memory": [3004.625, 32768.0], "load": 0.09, "temperature": 38.0, "power": 49.791}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734101991.8541062, "iodata": {"read_count": 0, "write_count": 23, "read_bytes": 0, "read_time": 0, "write_time": 11, "busy_time": 20}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734101991.8541062, "netdata": {"bytes_sent": 24673877490449, "bytes_recv": 25094368313063, "packets_sent": 2801990084, "packets_recv": 3105294651, "errin": 0, "errout": 0, "dropin": 0, "dropout": 0}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734101991.8541062, "cpudata": {"memory": [31789236224, 540098572288], "load": 30.7}}, "pipe": "data"}
{"event": "line", "data": "INFO:root:VideoDataset dataset created\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:root:VideoDataset unsupervised data loader created\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:iterations per epoch/dataest length: 300/3\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:root:Using AdamW\n", "pipe": "stdout"}
{"event": "line", "data": "/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/jepa/app/vjepa/utils.py:209: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n", "pipe": "stderr"}
{"event": "line", "data": "  scaler = torch.cuda.amp.GradScaler() if mixed_precision else None\n", "pipe": "stderr"}
{"event": "line", "data": "INFO:__main__:Initializing loader...\n", "pipe": "stdout"}
{"event": "data", "data": {"progress": [0, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102001.8724911, "gpudata": {"0": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.756}, "1": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.24}, "2": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 47.349}, "3": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 38.0, "power": 48.827}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102001.8724911, "iodata": {"read_count": 0, "write_count": 84, "read_bytes": 0, "read_time": 0, "write_time": 31, "busy_time": 48}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102001.8724911, "netdata": {"bytes_sent": 24673877794789, "bytes_recv": 25094368618011, "packets_sent": 2801993048, "packets_recv": 3105297633, "errin": 0, "errout": 0, "dropin": 0, "dropout": 0}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102001.8724911, "cpudata": {"memory": [33995784192, 540098572288], "load": 19.7}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102011.8902178, "gpudata": {"0": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.274}, "1": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.24}, "2": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 47.349}, "3": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 38.0, "power": 49.309}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102011.8902178, "iodata": {"read_count": 0, "write_count": 175, "read_bytes": 0, "read_time": 0, "write_time": 48, "busy_time": 76}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102011.8902178, "netdata": {"bytes_sent": 24673878955467, "bytes_recv": 25094369752393, "packets_sent": 2801993473, "packets_recv": 3105298065, "errin": 0, "errout": 0, "dropin": 0, "dropout": 0}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102011.8902178, "cpudata": {"memory": [35608387584, 540098572288], "load": 19.1}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102021.9088345, "gpudata": {"0": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.24}, "1": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.24}, "2": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 47.349}, "3": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 38.0, "power": 49.276}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102021.9088345, "iodata": {"read_count": 0, "write_count": 202, "read_bytes": 0, "read_time": 0, "write_time": 57, "busy_time": 92}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102021.9088345, "netdata": {"bytes_sent": 24673879806150, "bytes_recv": 25094370539117, "packets_sent": 2801994148, "packets_recv": 3105298728, "errin": 0, "errout": 0, "dropin": 0, "dropout": 0}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102021.9088345, "cpudata": {"memory": [37060374528, 540098572288], "load": 18.8}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102031.926815, "gpudata": {"0": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.24}, "1": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.24}, "2": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 47.349}, "3": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 38.0, "power": 49.309}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102031.926815, "iodata": {"read_count": 0, "write_count": 233, "read_bytes": 0, "read_time": 0, "write_time": 64, "busy_time": 116}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102031.926815, "netdata": {"bytes_sent": 24673879930210, "bytes_recv": 25094370664451, "packets_sent": 2801994423, "packets_recv": 3105299022, "errin": 0, "errout": 0, "dropin": 0, "dropout": 0}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102031.926815, "cpudata": {"memory": [39230263296, 540098572288], "load": 20.3}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102041.9383156, "gpudata": {"0": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.24}, "1": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.24}, "2": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 47.349}, "3": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 38.0, "power": 49.309}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102041.9383156, "iodata": {"read_count": 0, "write_count": 305, "read_bytes": 0, "read_time": 0, "write_time": 81, "busy_time": 148}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102041.9383156, "netdata": {"bytes_sent": 24673880508693, "bytes_recv": 25094371217627, "packets_sent": 2801994724, "packets_recv": 3105299329, "errin": 0, "errout": 0, "dropin": 0, "dropout": 0}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102041.9383156, "cpudata": {"memory": [40578551808, 540098572288], "load": 19.1}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102051.952422, "gpudata": {"0": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.24}, "1": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.24}, "2": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 47.349}, "3": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 38.0, "power": 49.309}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102051.952422, "iodata": {"read_count": 0, "write_count": 309, "read_bytes": 0, "read_time": 0, "write_time": 82, "busy_time": 156}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102051.952422, "netdata": {"bytes_sent": 24673881640950, "bytes_recv": 25094372287119, "packets_sent": 2801995235, "packets_recv": 3105299829, "errin": 0, "errout": 0, "dropin": 0, "dropout": 0}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102051.952422, "cpudata": {"memory": [42657910784, 540098572288], "load": 20.8}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102061.9706051, "gpudata": {"0": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.24}, "1": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.24}, "2": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 47.349}, "3": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 38.0, "power": 49.309}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102061.9706051, "iodata": {"read_count": 0, "write_count": 333, "read_bytes": 0, "read_time": 0, "write_time": 95, "busy_time": 176}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102061.9706051, "netdata": {"bytes_sent": 24673881766676, "bytes_recv": 25094372423090, "packets_sent": 2801995537, "packets_recv": 3105300154, "errin": 0, "errout": 0, "dropin": 0, "dropout": 0}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102061.9706051, "cpudata": {"memory": [44040151040, 540098572288], "load": 19.1}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102071.984404, "gpudata": {"0": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.24}, "1": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.24}, "2": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 47.349}, "3": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 38.0, "power": 49.276}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102071.984404, "iodata": {"read_count": 0, "write_count": 347, "read_bytes": 0, "read_time": 0, "write_time": 100, "busy_time": 196}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102071.984404, "netdata": {"bytes_sent": 24673882333288, "bytes_recv": 25094372965402, "packets_sent": 2801995821, "packets_recv": 3105300449, "errin": 0, "errout": 0, "dropin": 0, "dropout": 0}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102071.984404, "cpudata": {"memory": [45629747200, 540098572288], "load": 19.6}}, "pipe": "data"}
{"event": "line", "data": "INFO:__main__:Epoch 1\n", "pipe": "stdout"}
{"event": "data", "data": {"task": "main", "time": 1734102082.000439, "gpudata": {"0": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.24}, "1": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.24}, "2": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 47.317}, "3": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 38.0, "power": 49.309}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102082.000439, "iodata": {"read_count": 0, "write_count": 371, "read_bytes": 0, "read_time": 0, "write_time": 104, "busy_time": 220}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102082.000439, "netdata": {"bytes_sent": 24673883777460, "bytes_recv": 25094374350054, "packets_sent": 2801996630, "packets_recv": 3105301245, "errin": 0, "errout": 0, "dropin": 0, "dropout": 0}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102082.000439, "cpudata": {"memory": [49463459840, 540098572288], "load": 26.5}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102092.0164626, "gpudata": {"0": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.24}, "1": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.207}, "2": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 46.836}, "3": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 38.0, "power": 49.276}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102092.0164626, "iodata": {"read_count": 0, "write_count": 396, "read_bytes": 0, "read_time": 0, "write_time": 124, "busy_time": 228}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102092.0164626, "netdata": {"bytes_sent": 24673883901564, "bytes_recv": 25094374480313, "packets_sent": 2801996910, "packets_recv": 3105301543, "errin": 0, "errout": 0, "dropin": 0, "dropout": 0}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734102092.0164626, "cpudata": {"memory": [56792240128, 540098572288], "load": 41.5}}, "pipe": "data"}
{"event": "line", "data": "/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py:463: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n", "pipe": "stderr"}
{"event": "line", "data": "  with acc.amp.autocast(dtype=dtype, enabled=mixed_precision):\n", "pipe": "stderr"}
{"event": "error", "data": {"type": "RuntimeError", "message": "CUDA error: too many resources requested for launch\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [270.625, 32768.0], "load": 0.0, "temperature": 36.0, "power": 44.969}, "1": {"memory": [576.625, 32768.0], "load": 0.0, "temperature": 36.0, "power": 50.722}, "2": {"memory": [576.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 47.349}, "3": {"memory": [576.625, 32768.0], "load": 0.0, "temperature": 37.0, "power": 49.309}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [270.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 44.969}, "1": {"memory": [576.625, 32768.0], "load": 0.0, "temperature": 36.0, "power": 50.722}, "2": {"memory": [576.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 47.831}, "3": {"memory": [576.625, 32768.0], "load": 0.0, "temperature": 37.0, "power": 49.791}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [270.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 44.969}, "1": {"memory": [576.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.722}, "2": {"memory": [576.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 47.831}, "3": {"memory": [576.625, 32768.0], "load": 0.0, "temperature": 37.0, "power": 49.791}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [270.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 44.969}, "1": {"memory": [576.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.722}, "2": {"memory": [576.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 47.349}, "3": {"memory": [576.625, 32768.0], "load": 0.0, "temperature": 37.0, "power": 49.791}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [2198.625, 32768.0], "load": 0.17, "temperature": 35.0, "power": 51.204}, "1": {"memory": [3188.625, 32768.0], "load": 0.21, "temperature": 36.0, "power": 51.652}, "2": {"memory": [5756.625, 32768.0], "load": 0.18, "temperature": 33.0, "power": 49.276}, "3": {"memory": [1116.625, 32768.0], "load": 0.08, "temperature": 38.0, "power": 49.791}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 56.505}, "1": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 53.096}, "2": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 50.24}, "3": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 38.0, "power": 51.72}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.24}, "1": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.24}, "2": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 46.867}, "3": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 38.0, "power": 49.309}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.24}, "1": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.24}, "2": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 46.867}, "3": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 38.0, "power": 49.309}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.24}, "1": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.24}, "2": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 46.867}, "3": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 38.0, "power": 49.276}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.24}, "1": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.24}, "2": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 47.349}, "3": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 38.0, "power": 49.309}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.24}, "1": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.207}, "2": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 47.317}, "3": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 38.0, "power": 49.309}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.24}, "1": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.24}, "2": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 47.349}, "3": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 38.0, "power": 49.309}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.24}, "1": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.207}, "2": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 46.867}, "3": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 38.0, "power": 49.342}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.24}, "1": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 35.0, "power": 50.24}, "2": {"memory": [13482.625, 32768.0], "load": 0.0, "temperature": 33.0, "power": 46.867}, "3": {"memory": [13386.625, 32768.0], "load": 0.0, "temperature": 38.0, "power": 49.309}}}, "pipe": "data"}
{"event": "phase", "data": {"name": "finalize"}, "pipe": "data"}
{"event": "line", "data": "[rank0]: Traceback (most recent call last):\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/bin/voir\", line 8, in <module>\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     sys.exit(main())\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/cli.py\", line 128, in main\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     ov(sys.argv[1:] if argv is None else argv)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/phase.py\", line 331, in __call__\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     self._run(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/overseer.py\", line 242, in _run\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     set_value(func())\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/scriptutils.py\", line 37, in <lambda>\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     return lambda: exec(mainsection, glb, glb)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py\", line 656, in <module>\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     main()\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py\", line 645, in main\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     _main(params)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py\", line 509, in _main\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     (loss, loss_jepa, loss_reg, _new_lr, _new_wd, grad_stats, grad_stats_pred, optim_stats,), gpu_etime_ms = gpu_timer(train_step)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/jepa/src/utils/logging.py\", line 24, in gpu_timer\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     result = closure()\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py\", line 464, in train_step\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     h = forward_target(clips)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py\", line 435, in forward_target\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     h = target_encoder(c)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     return self._call_impl(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     return forward_call(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1636, in forward\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1454, in _run_ddp_forward\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     return self._call_impl(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     return forward_call(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/jepa/src/models/utils/multimask.py\", line 19, in forward\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     return self.backbone(x)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     return self._call_impl(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     return forward_call(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/jepa/src/models/vision_transformer.py\", line 172, in forward\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     x = self.patch_embed(x)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     return self._call_impl(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     return forward_call(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/jepa/src/models/utils/patch_embed.py\", line 56, in forward\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     x = self.proj(x).flatten(2).transpose(1, 2)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     return self._call_impl(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     return forward_call(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 608, in forward\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     return self._conv_forward(input, self.weight, self.bias)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 603, in _conv_forward\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     return F.conv3d(\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]: RuntimeError: CUDA error: too many resources requested for launch\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]: CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]: For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]: Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n", "pipe": "stderr"}
{"event": "line", "data": "\n", "pipe": "stderr"}
{"event": "line", "data": "W1213 10:02:37.028125 140398240715904 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 2280853 closing signal SIGTERM\n", "pipe": "stderr"}
{"event": "line", "data": "W1213 10:02:37.028790 140398240715904 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 2280853 closing signal SIGTERM\n", "pipe": "stderr"}
{"event": "line", "data": "Traceback (most recent call last):\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 680, in run\n", "pipe": "stderr"}
{"event": "line", "data": "    result = self._invoke_run(role)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 836, in _invoke_run\n", "pipe": "stderr"}
{"event": "line", "data": "    run_result = self._monitor_workers(self._worker_group)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 124, in wrapper\n", "pipe": "stderr"}
{"event": "line", "data": "    result = f(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py\", line 367, in _monitor_workers\n", "pipe": "stderr"}
{"event": "line", "data": "    result = self._pcontext.wait(0)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 503, in wait\n", "pipe": "stderr"}
{"event": "line", "data": "    return self._poll()\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 825, in _poll\n", "pipe": "stderr"}
{"event": "line", "data": "    self.close()  # terminate all running procs\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 544, in close\n", "pipe": "stderr"}
{"event": "line", "data": "    self._close(death_sig=death_sig, timeout=timeout)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 861, in _close\n", "pipe": "stderr"}
{"event": "line", "data": "    handler.close(death_sig=death_sig)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/subprocess_handler/subprocess_handler.py\", line 74, in close\n", "pipe": "stderr"}
{"event": "line", "data": "    os.killpg(self.proc.pid, death_sig)\n", "pipe": "stderr"}
{"event": "line", "data": "ProcessLookupError: [Errno 3] No such process\n", "pipe": "stderr"}
{"event": "line", "data": "\n", "pipe": "stderr"}
{"event": "line", "data": "During handling of the above exception, another exception occurred:\n", "pipe": "stderr"}
{"event": "line", "data": "\n", "pipe": "stderr"}
{"event": "line", "data": "Traceback (most recent call last):\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/bin/benchrun\", line 8, in <module>\n", "pipe": "stderr"}
{"event": "line", "data": "    sys.exit(main())\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/home/mila/o/ortizgas/CODE/milabench/benchmate/benchmate/benchrun.py\", line 68, in main\n", "pipe": "stderr"}
{"event": "line", "data": "    run(args)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/home/mila/o/ortizgas/CODE/milabench/benchmate/benchmate/benchrun.py\", line 63, in run\n", "pipe": "stderr"}
{"event": "line", "data": "    distrun.run(args)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/run.py\", line 892, in run\n", "pipe": "stderr"}
{"event": "line", "data": "    elastic_launch(\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 133, in __call__\n", "pipe": "stderr"}
{"event": "line", "data": "    return launch_agent(self._config, self._entrypoint, list(args))\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 255, in launch_agent\n", "pipe": "stderr"}
{"event": "line", "data": "    result = agent.run()\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 124, in wrapper\n", "pipe": "stderr"}
{"event": "line", "data": "    result = f(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 694, in run\n", "pipe": "stderr"}
{"event": "line", "data": "    self._shutdown()\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py\", line 347, in _shutdown\n", "pipe": "stderr"}
{"event": "line", "data": "    self._pcontext.close(death_sig)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 544, in close\n", "pipe": "stderr"}
{"event": "line", "data": "    self._close(death_sig=death_sig, timeout=timeout)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 861, in _close\n", "pipe": "stderr"}
{"event": "line", "data": "    handler.close(death_sig=death_sig)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/subprocess_handler/subprocess_handler.py\", line 74, in close\n", "pipe": "stderr"}
{"event": "line", "data": "    os.killpg(self.proc.pid, death_sig)\n", "pipe": "stderr"}
{"event": "line", "data": "ProcessLookupError: [Errno 3] No such process\n", "pipe": "stderr"}
{"event": "end", "data": {"command": ["/network/scratch/o/ortizgas/data/milabench/venv/torch/bin/benchrun", "--nnodes=1", "--rdzv-backend=static", "--rdzv-endpoint=cn-e002.server.mila.quebec:29400", "--master-addr=cn-e002.server.mila.quebec", "--master-port=29400", "--local-ranks-filter=0", "--nproc-per-node=4", "--", "/network/scratch/o/ortizgas/data/milabench/venv/torch/bin/voir", "--config", "/network/scratch/o/ortizgas/data/milabench/extra/vjepa-gpus/voirconf-vjepa-gpus.0-0efae956f1553a76c1e03985181900f5.json", "/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py", "--batch_size", "64", "--num_workers", "12", "--dataset", "/network/scratch/o/ortizgas/data/milabench/data/FakeVideo/video_metainfo.csv", "--output", "/network/scratch/o/ortizgas/data/milabench/extra/vjepa-gpus"], "time": 1734102157.4397979, "return_code": 1}, "pipe": null}

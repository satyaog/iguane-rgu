/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/jepa/app/vjepa/utils.py:209: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler() if mixed_precision else None
/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py:463: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with acc.amp.autocast(dtype=dtype, enabled=mixed_precision):
/home/mila/o/ortizgas/env/cp310/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
[rank0]: Traceback (most recent call last):
[rank0]:   File "/network/scratch/o/ortizgas/data/milabench/venv/torch/bin/voir", line 8, in <module>
[rank0]:     sys.exit(main())
[rank0]:   File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/cli.py", line 128, in main
[rank0]:     ov(sys.argv[1:] if argv is None else argv)
[rank0]:   File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/phase.py", line 331, in __call__
[rank0]:     self._run(*args, **kwargs)
[rank0]:   File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/overseer.py", line 242, in _run
[rank0]:     set_value(func())
[rank0]:   File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/scriptutils.py", line 37, in <lambda>
[rank0]:     return lambda: exec(mainsection, glb, glb)
[rank0]:   File "/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py", line 656, in <module>
[rank0]:     main()
[rank0]:   File "/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py", line 645, in main
[rank0]:     _main(params)
[rank0]:   File "/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py", line 391, in _main
[rank0]:     udata, masks_enc, masks_pred = next(loader)
[rank0]:   File "/home/mila/o/ortizgas/CODE/milabench/benchmate/benchmate/metrics.py", line 302, in wrapped
[rank0]:     self._push()
[rank0]:   File "/home/mila/o/ortizgas/CODE/milabench/benchmate/benchmate/metrics.py", line 415, in _push
[rank0]:     self._push_time_steps()
[rank0]:   File "/home/mila/o/ortizgas/CODE/milabench/benchmate/benchmate/metrics.py", line 374, in _push_time_steps
[rank0]:     rate = self.batch_size(bs) / elapsed
[rank0]:   File "/home/mila/o/ortizgas/CODE/milabench/benchmate/benchmate/metrics.py", line 366, in batch_size
[rank0]:     dist.reduce(bs, dst=0)
[rank0]:   File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 2396, in reduce
[rank0]:     work = default_pg.reduce([tensor], opts)
[rank0]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/NCCLUtils.hpp:275, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.20.5
[rank0]: ncclUnhandledCudaError: Call to CUDA function failed.
[rank0]: Last error:
[rank0]: Cuda failure 2 'out of memory'
/home/mila/o/ortizgas/env/cp310/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 46 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '

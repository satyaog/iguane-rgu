{"event": "config", "data": {"system": {"arch": "cuda", "sshkey": null, "nodes": [{"name": "local", "ip": "127.0.0.1", "sshport": 22, "user": "root", "main": true, "hostname": "cn-c009.server.mila.quebec", "local": true}], "self": {"name": "local", "ip": "127.0.0.1", "sshport": 22, "user": "root", "main": true, "hostname": "cn-c009.server.mila.quebec", "local": true}}, "dirs": {"base": "/network/scratch/o/ortizgas/data/milabench", "venv": "/network/scratch/o/ortizgas/data/milabench/venv/torch", "data": "/network/scratch/o/ortizgas/data/milabench/data", "runs": "/network/scratch/o/ortizgas/data/milabench/runs", "extra": "/network/scratch/o/ortizgas/data/milabench/extra/hf", "cache": "/network/scratch/o/ortizgas/data/milabench/cache"}, "group": "hf", "install_group": "torch", "install_variant": "cuda", "run_name": "Quadro-RTX-8000_t5_32.staging", "enabled": true, "capabilities": {"nodes": 1}, "max_duration": 600, "voir": {"options": {"stop": 60, "interval": "1s"}}, "validation": {"usage": {"gpu_load_threshold": 0.5, "gpu_mem_threshold": 0.5}}, "config_base": "/home/mila/o/ortizgas/CODE/milabench/config", "config_file": "/home/mila/o/ortizgas/CODE/milabench/config/standard.yaml", "definition": "/home/mila/o/ortizgas/CODE/milabench/benchmarks/huggingface", "argv": {"--precision": "tf32-fp16", "--num-workers": "auto({n_worker}, 8)", "--model": "T5", "--batch-size": 16}, "plan": {"method": "njobs", "n": 1}, "tags": ["huggingface", "language-modeling", "monogpu", "nlp", "noio", "transformer"], "weight": 2.0, "name": "t5", "tag": ["t5", "0"], "job-number": 0, "devices": [0]}, "pipe": null}
{"event": "meta", "data": {"cpu": {"count": 64, "brand": "AMD EPYC 7502 32-Core Processor"}, "os": {"sysname": "Linux", "nodename": "cn-c009.server.mila.quebec", "release": "5.15.0-101-generic", "version": "#111-Ubuntu SMP Tue Mar 5 20:16:58 UTC 2024", "machine": "x86_64"}, "accelerators": {"arch": "cuda", "gpus": {"0": {"minor_number": "4", "device": 0, "product": "Quadro RTX 8000", "memory": {"used": 541.9375, "total": 46080.0}, "utilization": {"compute": 0.0, "memory": 0}, "temperature": 52.0, "power": 31.408, "selection_variable": "CUDA_VISIBLE_DEVICES"}}}, "date": 1733968888.333628, "milabench": {"tag": "v1.0.0_RC1-13-g7a90b16", "commit": "7a90b1691650232ecd63abded0b7be84bb294c05", "date": "2024-11-08 11:28:56 -0500"}, "pytorch": {"torch": "2.4.0+cu121", "compiler": "GCC 9.3", "cpp": "C++ Version: 201703", "intel": "Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications", "mkl": "OpenMP 201511 (a.k.a. OpenMP 4.5)", "openmp": "OpenMP 201511 (a.k.a. OpenMP 4.5)", "lapack": "LAPACK is enabled (usually provided by MKL)", "nnpack": "NNPACK is enabled", "cpu": "CPU capability usage: AVX2", "build_settings": {"BLAS_INFO": "mkl", "BUILD_TYPE": "Release", "CUDA_VERSION": "12.1", "CUDNN_VERSION": "9.1.0", "CXX_COMPILER": "/opt/rh/devtoolset-9/root/usr/bin/c++", "CXX_FLAGS": "-D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow", "LAPACK_INFO": "mkl", "PERF_WITH_AVX": "1", "PERF_WITH_AVX2": "1", "PERF_WITH_AVX512": "1", "TORCH_VERSION": "2.4.0", "USE_CUDA": "ON", "USE_CUDNN": "ON", "USE_CUSPARSELT": "1", "USE_EXCEPTION_PTR": "1", "USE_GFLAGS": "OFF", "USE_GLOG": "OFF", "USE_GLOO": "ON", "USE_MKL": "ON", "USE_MKLDNN": "ON", "USE_MPI": "OFF", "USE_NCCL": "1", "USE_NNPACK": "ON", "USE_OPENMP": "ON", "USE_ROCM": "OFF", "USE_ROCM_KERNEL_ASSERT": "OFF"}}}, "pipe": null}
{"event": "start", "data": {"command": ["/network/scratch/o/ortizgas/data/milabench/venv/torch/bin/voir", "--config", "/network/scratch/o/ortizgas/data/milabench/extra/hf/voirconf-t5.0-0efae956f1553a76c1e03985181900f5.json", "-m", "bench", "--precision", "tf32-fp16", "--num-workers", "8", "--model", "T5", "--batch-size", "32"], "time": 1733950888.4198906}, "pipe": null}
{"event": "phase", "data": {"name": "init"}, "pipe": "data"}
{"event": "phase", "data": {"name": "parse_args"}, "pipe": "data"}
{"event": "phase", "data": {"name": "load_script"}, "pipe": "data"}
{"event": "phase", "data": {"name": "run_script"}, "pipe": "data"}
{"event": "line", "data": "/home/mila/o/ortizgas/CODE/milabench/benchmarks/huggingface/bench/__main__.py:79: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n", "pipe": "stderr"}
{"event": "line", "data": "  self.amp_scaler = accelerator.amp.GradScaler(enabled=is_fp16_allowed(args))\n", "pipe": "stderr"}
{"event": "data", "data": {"progress": [0, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [544.8125, 46080.0], "load": 0.0, "temperature": 48.0, "power": 29.339}}}, "pipe": "data"}
{"event": "line", "data": "/home/mila/o/ortizgas/CODE/milabench/benchmarks/huggingface/bench/__main__.py:82: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n", "pipe": "stderr"}
{"event": "line", "data": "  self.amp_context = lambda: accelerator.amp.autocast(dtype=float_dtype(args.precision))\n", "pipe": "stderr"}
{"event": "error", "data": {"type": "OutOfMemoryError", "message": "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacity of 44.47 GiB of which 387.19 MiB is free. Including non-PyTorch memory, this process has 44.09 GiB memory in use. Of the allocated memory 43.39 GiB is allocated by PyTorch, and 514.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}, "pipe": "data"}
{"event": "phase", "data": {"name": "finalize"}, "pipe": "data"}
{"event": "line", "data": "Traceback (most recent call last):\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/bin/voir\", line 8, in <module>\n", "pipe": "stderr"}
{"event": "line", "data": "    sys.exit(main())\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/cli.py\", line 128, in main\n", "pipe": "stderr"}
{"event": "line", "data": "    ov(sys.argv[1:] if argv is None else argv)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/phase.py\", line 331, in __call__\n", "pipe": "stderr"}
{"event": "line", "data": "    self._run(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/overseer.py\", line 242, in _run\n", "pipe": "stderr"}
{"event": "line", "data": "    set_value(func())\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/scriptutils.py\", line 37, in <lambda>\n", "pipe": "stderr"}
{"event": "line", "data": "    return lambda: exec(mainsection, glb, glb)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/huggingface/bench/__main__.py\", line 208, in <module>\n", "pipe": "stderr"}
{"event": "line", "data": "    main()\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/huggingface/bench/__main__.py\", line 204, in main\n", "pipe": "stderr"}
{"event": "line", "data": "    runner.train()\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/huggingface/bench/__main__.py\", line 120, in train\n", "pipe": "stderr"}
{"event": "line", "data": "    loss = self.step(data)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/huggingface/bench/__main__.py\", line 88, in step\n", "pipe": "stderr"}
{"event": "line", "data": "    outputs = self.model(**data)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n", "pipe": "stderr"}
{"event": "line", "data": "    return self._call_impl(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n", "pipe": "stderr"}
{"event": "line", "data": "    return forward_call(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py\", line 1739, in forward\n", "pipe": "stderr"}
{"event": "line", "data": "    decoder_outputs = self.decoder(\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n", "pipe": "stderr"}
{"event": "line", "data": "    return self._call_impl(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n", "pipe": "stderr"}
{"event": "line", "data": "    return forward_call(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py\", line 1106, in forward\n", "pipe": "stderr"}
{"event": "line", "data": "    layer_outputs = layer_module(\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n", "pipe": "stderr"}
{"event": "line", "data": "    return self._call_impl(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n", "pipe": "stderr"}
{"event": "line", "data": "    return forward_call(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py\", line 686, in forward\n", "pipe": "stderr"}
{"event": "line", "data": "    self_attention_outputs = self.layer[0](\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n", "pipe": "stderr"}
{"event": "line", "data": "    return self._call_impl(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n", "pipe": "stderr"}
{"event": "line", "data": "    return forward_call(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py\", line 593, in forward\n", "pipe": "stderr"}
{"event": "line", "data": "    attention_output = self.SelfAttention(\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n", "pipe": "stderr"}
{"event": "line", "data": "    return self._call_impl(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n", "pipe": "stderr"}
{"event": "line", "data": "    return forward_call(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py\", line 553, in forward\n", "pipe": "stderr"}
{"event": "line", "data": "    attn_weights = nn.functional.softmax(scores.float(), dim=-1).type_as(\n", "pipe": "stderr"}
{"event": "line", "data": "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacity of 44.47 GiB of which 387.19 MiB is free. Including non-PyTorch memory, this process has 44.09 GiB memory in use. Of the allocated memory 43.39 GiB is allocated by PyTorch, and 514.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n", "pipe": "stderr"}
{"event": "end", "data": {"command": ["/network/scratch/o/ortizgas/data/milabench/venv/torch/bin/voir", "--config", "/network/scratch/o/ortizgas/data/milabench/extra/hf/voirconf-t5.0-0efae956f1553a76c1e03985181900f5.json", "-m", "bench", "--precision", "tf32-fp16", "--num-workers", "8", "--model", "T5", "--batch-size", "32"], "time": 1733950901.478031, "return_code": 1}, "pipe": null}

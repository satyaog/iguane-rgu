/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/27 [00:00<?, ?it/s]                                        0%|          | 0/27 [00:30<?, ?it/s]  4%|▎         | 1/27 [00:30<13:02, 30.11s/it]                                                4%|▎         | 1/27 [00:51<13:02, 30.11s/it]  7%|▋         | 2/27 [00:51<10:23, 24.93s/it]                                                7%|▋         | 2/27 [01:12<10:23, 24.93s/it] 11%|█         | 3/27 [01:12<09:19, 23.29s/it]                                               11%|█         | 3/27 [01:33<09:19, 23.29s/it] 15%|█▍        | 4/27 [01:33<08:33, 22.34s/it]                                               15%|█▍        | 4/27 [01:54<08:33, 22.34s/it] 19%|█▊        | 5/27 [01:54<08:01, 21.88s/it]                                               19%|█▊        | 5/27 [02:16<08:01, 21.88s/it] 22%|██▏       | 6/27 [02:16<07:35, 21.69s/it]                                               22%|██▏       | 6/27 [02:37<07:35, 21.69s/it] 26%|██▌       | 7/27 [02:37<07:13, 21.66s/it]                                               26%|██▌       | 7/27 [02:59<07:13, 21.66s/it] 30%|██▉       | 8/27 [02:59<06:50, 21.60s/it]                                               30%|██▉       | 8/27 [03:20<06:50, 21.60s/it] 33%|███▎      | 9/27 [03:20<06:27, 21.54s/it]                                               33%|███▎      | 9/27 [03:42<06:27, 21.54s/it] 37%|███▋      | 10/27 [03:42<06:06, 21.58s/it]                                                37%|███▋      | 10/27 [04:03<06:06, 21.58s/it] 41%|████      | 11/27 [04:03<05:44, 21.55s/it]                                                41%|████      | 11/27 [04:24<05:44, 21.55s/it] 44%|████▍     | 12/27 [04:24<05:21, 21.46s/it]                                                44%|████▍     | 12/27 [04:46<05:21, 21.46s/it] 48%|████▊     | 13/27 [04:46<04:59, 21.40s/it]                                                48%|████▊     | 13/27 [05:07<04:59, 21.40s/it] 52%|█████▏    | 14/27 [05:07<04:36, 21.29s/it]                                                52%|█████▏    | 14/27 [05:28<04:36, 21.29s/it] 56%|█████▌    | 15/27 [05:28<04:14, 21.24s/it]                                                56%|█████▌    | 15/27 [05:49<04:14, 21.24s/it] 59%|█████▉    | 16/27 [05:49<03:52, 21.16s/it]                                                59%|█████▉    | 16/27 [06:10<03:52, 21.16s/it] 63%|██████▎   | 17/27 [06:10<03:32, 21.25s/it]                                                63%|██████▎   | 17/27 [06:32<03:32, 21.25s/it] 67%|██████▋   | 18/27 [06:32<03:11, 21.27s/it]                                                67%|██████▋   | 18/27 [06:52<03:11, 21.27s/it] 70%|███████   | 19/27 [06:52<02:49, 21.16s/it]                                                70%|███████   | 19/27 [07:14<02:49, 21.16s/it] 74%|███████▍  | 20/27 [07:14<02:28, 21.16s/it]                                                74%|███████▍  | 20/27 [07:35<02:28, 21.16s/it] 78%|███████▊  | 21/27 [07:35<02:07, 21.19s/it]                                                78%|███████▊  | 21/27 [07:56<02:07, 21.19s/it] 81%|████████▏ | 22/27 [07:56<01:45, 21.06s/it]                                                81%|████████▏ | 22/27 [08:17<01:45, 21.06s/it] 85%|████████▌ | 23/27 [08:17<01:24, 21.13s/it]                                                85%|████████▌ | 23/27 [08:39<01:24, 21.13s/it] 89%|████████▉ | 24/27 [08:39<01:03, 21.33s/it]                                                89%|████████▉ | 24/27 [09:00<01:03, 21.33s/it] 93%|█████████▎| 25/27 [09:00<00:42, 21.21s/it]                                                93%|█████████▎| 25/27 [09:21<00:42, 21.21s/it] 96%|█████████▋| 26/27 [09:21<00:21, 21.13s/it]W1211 08:33:24.769148 140624563901568 torch/distributed/elastic/agent/server/api.py:688] Received Signals.SIGTERM death signal, shutting down workers
W1211 08:33:24.769599 140624563901568 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 329735 closing signal SIGTERM
W1211 08:33:24.769818 140624563901568 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 329736 closing signal SIGTERM
W1211 08:33:24.771335 140624563901568 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 329737 closing signal SIGTERM
W1211 08:33:24.771946 140624563901568 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 329738 closing signal SIGTERM
Traceback (most recent call last):
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1165, in launch_command
    multi_gpu_launcher(args)
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/accelerate/commands/launch.py", line 799, in multi_gpu_launcher
    distrib_run.run(args)
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 255, in launch_agent
    result = agent.run()
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    result = f(*args, **kwargs)
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 680, in run
    result = self._invoke_run(role)
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 835, in _invoke_run
    time.sleep(monitor_interval)
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 79, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 329674 got signal: 15

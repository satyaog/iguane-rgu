{"event": "config", "data": {"system": {"arch": "cuda", "sshkey": null, "nodes": [{"name": "local", "ip": "127.0.0.1", "sshport": 22, "user": "root", "main": true, "hostname": "cn-d001.server.mila.quebec", "local": true}], "self": {"name": "local", "ip": "127.0.0.1", "sshport": 22, "user": "root", "main": true, "hostname": "cn-d001.server.mila.quebec", "local": true}}, "dirs": {"base": "/network/scratch/o/ortizgas/data/milabench", "venv": "/network/scratch/o/ortizgas/data/milabench/venv/torch", "data": "/network/scratch/o/ortizgas/data/milabench/data", "runs": "/network/scratch/o/ortizgas/data/milabench/runs", "extra": "/network/scratch/o/ortizgas/data/milabench/extra/llava-single", "cache": "/network/scratch/o/ortizgas/data/milabench/cache"}, "group": "llava-single", "install_group": "torch", "install_variant": "cuda", "run_name": "NVIDIA-A100-SXM4-40GB_llava-single_8.staging", "enabled": true, "capabilities": {"nodes": 1}, "max_duration": 600, "voir": {"options": {"stop": 60, "interval": "1s"}}, "validation": {"usage": {"gpu_load_threshold": 0.5, "gpu_mem_threshold": 0.5}}, "config_base": "/home/mila/o/ortizgas/CODE/milabench/config", "config_file": "/home/mila/o/ortizgas/CODE/milabench/config/standard.yaml", "definition": "/home/mila/o/ortizgas/CODE/milabench/benchmarks/llava", "plan": {"method": "njobs", "n": 1}, "tags": ["llm", "monogpu"], "argv": {"--batch_size": 1, "--num_workers": "auto({n_worker}, 4)", "--gradient_accumulation_steps": 1}, "weight": 1.0, "name": "llava-single", "tag": ["llava-single", "0"], "job-number": 0, "devices": [0]}, "pipe": null}
{"event": "meta", "data": {"cpu": {"count": 256, "brand": "AMD EPYC 7742 64-Core Processor"}, "os": {"sysname": "Linux", "nodename": "cn-d001.server.mila.quebec", "release": "5.15.0-1048-nvidia", "version": "#48-Ubuntu SMP Thu Mar 21 18:19:02 UTC 2024", "machine": "x86_64"}, "accelerators": {"arch": "cuda", "gpus": {"0": {"minor_number": "1", "device": 0, "product": "NVIDIA A100-SXM4-40GB", "memory": {"used": 620.875, "total": 40960.0}, "utilization": {"compute": 0.0, "memory": 0}, "temperature": 25.0, "power": 54.464, "selection_variable": "CUDA_VISIBLE_DEVICES"}}}, "date": 1733961129.595157, "milabench": {"tag": "v1.0.0_RC1-13-g7a90b16", "commit": "7a90b1691650232ecd63abded0b7be84bb294c05", "date": "2024-11-08 11:28:56 -0500"}, "pytorch": {"torch": "2.4.0+cu121", "compiler": "GCC 9.3", "cpp": "C++ Version: 201703", "intel": "Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications", "mkl": "OpenMP 201511 (a.k.a. OpenMP 4.5)", "openmp": "OpenMP 201511 (a.k.a. OpenMP 4.5)", "lapack": "LAPACK is enabled (usually provided by MKL)", "nnpack": "NNPACK is enabled", "cpu": "CPU capability usage: AVX2", "build_settings": {"BLAS_INFO": "mkl", "BUILD_TYPE": "Release", "CUDA_VERSION": "12.1", "CUDNN_VERSION": "9.1.0", "CXX_COMPILER": "/opt/rh/devtoolset-9/root/usr/bin/c++", "CXX_FLAGS": "-D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow", "LAPACK_INFO": "mkl", "PERF_WITH_AVX": "1", "PERF_WITH_AVX2": "1", "PERF_WITH_AVX512": "1", "TORCH_VERSION": "2.4.0", "USE_CUDA": "ON", "USE_CUDNN": "ON", "USE_CUSPARSELT": "1", "USE_EXCEPTION_PTR": "1", "USE_GFLAGS": "OFF", "USE_GLOG": "OFF", "USE_GLOO": "ON", "USE_MKL": "ON", "USE_MKLDNN": "ON", "USE_MPI": "OFF", "USE_NCCL": "1", "USE_NNPACK": "ON", "USE_OPENMP": "ON", "USE_ROCM": "OFF", "USE_ROCM_KERNEL_ASSERT": "OFF"}}}, "pipe": null}
{"event": "start", "data": {"command": ["/home/mila/o/ortizgas/CODE/milabench/benchmarks/llava/main.py", "--batch_size", "8", "--num_workers", "4", "--gradient_accumulation_steps", "1"], "time": 1733943129.6733842}, "pipe": null}
{"event": "line", "data": "Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (64)", "pipe": "stderr"}
{"event": "line", "data": "\rLoading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]", "pipe": "stderr"}
{"event": "line", "data": "\rLoading checkpoint shards:  33%|\u2588\u2588\u2588\u258e      | 1/3 [00:04<00:09,  4.59s/it]", "pipe": "stderr"}
{"event": "line", "data": "\rLoading checkpoint shards:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 2/3 [00:09<00:04,  4.53s/it]", "pipe": "stderr"}
{"event": "data", "data": {"task": "main", "time": 1733943151.5810487, "gpudata": {"0": {"memory": [10549.6875, 40960.0], "load": 0.06, "temperature": 25.0, "power": 63.292}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1733943151.5810487, "process": {"pid": 2731590, "load": 0.0, "num": 81, "read_bytes": 10379213888.0, "write_bytes": 4096.0, "read_chars": 57422307.0, "write_chars": 1850.0, "memory": [5068451840.0, 1081172426752]}}, "pipe": "data"}
{"event": "line", "data": "\rLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:12<00:00,  3.87s/it]", "pipe": "stderr"}
{"event": "line", "data": "\rLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:12<00:00,  4.05s/it]\n", "pipe": "stderr"}
{"event": "line", "data": "Traceback (most recent call last):\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/llava/main.py\", line 143, in <module>\n", "pipe": "stderr"}
{"event": "line", "data": "    main()\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/llava/main.py\", line 67, in main\n", "pipe": "stderr"}
{"event": "line", "data": "    processor = AutoProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py\", line 321, in from_pretrained\n", "pipe": "stderr"}
{"event": "line", "data": "    return processor_class.from_pretrained(\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/processing_utils.py\", line 892, in from_pretrained\n", "pipe": "stderr"}
{"event": "line", "data": "    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/processing_utils.py\", line 938, in _get_arguments_from_pretrained\n", "pipe": "stderr"}
{"event": "line", "data": "    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py\", line 897, in from_pretrained\n", "pipe": "stderr"}
{"event": "line", "data": "    return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\", line 2271, in from_pretrained\n", "pipe": "stderr"}
{"event": "line", "data": "    return cls._from_pretrained(\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\", line 2505, in _from_pretrained\n", "pipe": "stderr"}
{"event": "line", "data": "    tokenizer = cls(*init_inputs, **init_kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama_fast.py\", line 157, in __init__\n", "pipe": "stderr"}
{"event": "line", "data": "    super().__init__(\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py\", line 115, in __init__\n", "pipe": "stderr"}
{"event": "line", "data": "    fast_tokenizer = TokenizerFast.from_file(fast_tokenizer_file)\n", "pipe": "stderr"}
{"event": "line", "data": "Exception: data did not match any variant of untagged enum ModelWrapper at line 277156 column 3\n", "pipe": "stderr"}
{"event": "end", "data": {"command": ["/home/mila/o/ortizgas/CODE/milabench/benchmarks/llava/main.py", "--batch_size", "8", "--num_workers", "4", "--gradient_accumulation_steps", "1"], "time": 1733943156.28704, "return_code": 1}, "pipe": null}

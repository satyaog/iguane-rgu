/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/24 [00:00<?, ?it/s]                                        0%|          | 0/24 [00:33<?, ?it/s]  4%|▍         | 1/24 [00:33<12:42, 33.16s/it]                                                4%|▍         | 1/24 [00:56<12:42, 33.16s/it]  8%|▊         | 2/24 [00:56<10:06, 27.57s/it]                                                8%|▊         | 2/24 [01:20<10:06, 27.57s/it] 12%|█▎        | 3/24 [01:20<09:01, 25.77s/it]                                               12%|█▎        | 3/24 [01:44<09:01, 25.77s/it] 17%|█▋        | 4/24 [01:44<08:20, 25.01s/it]                                               17%|█▋        | 4/24 [02:08<08:20, 25.01s/it] 21%|██        | 5/24 [02:08<07:47, 24.63s/it]                                               21%|██        | 5/24 [02:31<07:47, 24.63s/it] 25%|██▌       | 6/24 [02:31<07:17, 24.30s/it]                                               25%|██▌       | 6/24 [02:55<07:17, 24.30s/it] 29%|██▉       | 7/24 [02:55<06:51, 24.22s/it]                                               29%|██▉       | 7/24 [03:19<06:51, 24.22s/it] 33%|███▎      | 8/24 [03:19<06:26, 24.15s/it]                                               33%|███▎      | 8/24 [03:45<06:26, 24.15s/it] 38%|███▊      | 9/24 [03:45<06:06, 24.43s/it]                                               38%|███▊      | 9/24 [04:08<06:06, 24.43s/it] 42%|████▏     | 10/24 [04:08<05:39, 24.27s/it]                                                42%|████▏     | 10/24 [04:32<05:39, 24.27s/it] 46%|████▌     | 11/24 [04:32<05:13, 24.11s/it]                                                46%|████▌     | 11/24 [04:56<05:13, 24.11s/it] 50%|█████     | 12/24 [04:56<04:48, 24.02s/it]                                                50%|█████     | 12/24 [05:20<04:48, 24.02s/it] 54%|█████▍    | 13/24 [05:20<04:23, 23.97s/it]                                                54%|█████▍    | 13/24 [05:44<04:23, 23.97s/it] 58%|█████▊    | 14/24 [05:44<03:59, 23.94s/it]                                                58%|█████▊    | 14/24 [06:08<03:59, 23.94s/it] 62%|██████▎   | 15/24 [06:08<03:35, 23.99s/it]                                                62%|██████▎   | 15/24 [06:32<03:35, 23.99s/it] 67%|██████▋   | 16/24 [06:32<03:11, 23.94s/it]                                                67%|██████▋   | 16/24 [06:55<03:11, 23.94s/it] 71%|███████   | 17/24 [06:55<02:47, 23.91s/it]                                                71%|███████   | 17/24 [07:19<02:47, 23.91s/it] 75%|███████▌  | 18/24 [07:19<02:23, 23.85s/it]                                                75%|███████▌  | 18/24 [07:43<02:23, 23.85s/it] 79%|███████▉  | 19/24 [07:43<01:59, 23.83s/it]                                                79%|███████▉  | 19/24 [08:07<01:59, 23.83s/it] 83%|████████▎ | 20/24 [08:07<01:35, 23.86s/it]                                                83%|████████▎ | 20/24 [08:31<01:35, 23.86s/it] 88%|████████▊ | 21/24 [08:31<01:11, 23.87s/it]                                                88%|████████▊ | 21/24 [08:55<01:11, 23.87s/it] 92%|█████████▏| 22/24 [08:55<00:47, 23.89s/it]                                                92%|█████████▏| 22/24 [09:18<00:47, 23.89s/it] 96%|█████████▌| 23/24 [09:18<00:23, 23.83s/it]W1211 07:41:54.592421 140339572454528 torch/distributed/elastic/agent/server/api.py:688] Received Signals.SIGTERM death signal, shutting down workers
W1211 07:41:54.592829 140339572454528 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 317042 closing signal SIGTERM
W1211 07:41:54.593755 140339572454528 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 317043 closing signal SIGTERM
W1211 07:41:54.594571 140339572454528 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 317044 closing signal SIGTERM
W1211 07:41:54.595062 140339572454528 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 317045 closing signal SIGTERM
Traceback (most recent call last):
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1165, in launch_command
    multi_gpu_launcher(args)
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/accelerate/commands/launch.py", line 799, in multi_gpu_launcher
    distrib_run.run(args)
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 255, in launch_agent
    result = agent.run()
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    result = f(*args, **kwargs)
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 680, in run
    result = self._invoke_run(role)
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 835, in _invoke_run
    time.sleep(monitor_interval)
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 79, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 316980 got signal: 15

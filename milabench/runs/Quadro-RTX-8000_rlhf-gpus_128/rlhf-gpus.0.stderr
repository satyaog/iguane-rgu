/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-160m and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/32 [00:00<?, ?it/s]                                        0%|          | 0/32 [00:24<?, ?it/s]  3%|▎         | 1/32 [00:24<12:51, 24.90s/it]                                                3%|▎         | 1/32 [00:42<12:51, 24.90s/it]  6%|▋         | 2/32 [00:42<10:19, 20.65s/it]                                                6%|▋         | 2/32 [01:00<10:19, 20.65s/it]  9%|▉         | 3/32 [01:00<09:20, 19.32s/it]                                                9%|▉         | 3/32 [01:18<09:20, 19.32s/it] 12%|█▎        | 4/32 [01:18<08:44, 18.74s/it]                                               12%|█▎        | 4/32 [01:36<08:44, 18.74s/it] 16%|█▌        | 5/32 [01:36<08:19, 18.51s/it]                                               16%|█▌        | 5/32 [01:54<08:19, 18.51s/it] 19%|█▉        | 6/32 [01:54<07:56, 18.32s/it]                                               19%|█▉        | 6/32 [02:12<07:56, 18.32s/it] 22%|██▏       | 7/32 [02:12<07:36, 18.25s/it]                                               22%|██▏       | 7/32 [02:30<07:36, 18.25s/it] 25%|██▌       | 8/32 [02:30<07:15, 18.14s/it]                                               25%|██▌       | 8/32 [02:48<07:15, 18.14s/it] 28%|██▊       | 9/32 [02:48<06:59, 18.26s/it]                                               28%|██▊       | 9/32 [03:06<06:59, 18.26s/it] 31%|███▏      | 10/32 [03:06<06:38, 18.11s/it]                                                31%|███▏      | 10/32 [03:24<06:38, 18.11s/it] 34%|███▍      | 11/32 [03:24<06:19, 18.08s/it]                                                34%|███▍      | 11/32 [03:42<06:19, 18.08s/it] 38%|███▊      | 12/32 [03:42<06:02, 18.11s/it]                                                38%|███▊      | 12/32 [04:00<06:02, 18.11s/it] 41%|████      | 13/32 [04:00<05:42, 18.05s/it]                                                41%|████      | 13/32 [04:18<05:42, 18.05s/it] 44%|████▍     | 14/32 [04:18<05:25, 18.08s/it]                                                44%|████▍     | 14/32 [04:36<05:25, 18.08s/it] 47%|████▋     | 15/32 [04:36<05:06, 18.01s/it]                                                47%|████▋     | 15/32 [04:54<05:06, 18.01s/it] 50%|█████     | 16/32 [04:54<04:47, 17.95s/it]                                                50%|█████     | 16/32 [05:12<04:47, 17.95s/it] 53%|█████▎    | 17/32 [05:12<04:28, 17.88s/it]                                                53%|█████▎    | 17/32 [05:30<04:28, 17.88s/it] 56%|█████▋    | 18/32 [05:30<04:10, 17.92s/it]                                                56%|█████▋    | 18/32 [05:48<04:10, 17.92s/it] 59%|█████▉    | 19/32 [05:48<03:53, 17.93s/it]                                                59%|█████▉    | 19/32 [06:05<03:53, 17.93s/it] 62%|██████▎   | 20/32 [06:05<03:34, 17.90s/it]                                                62%|██████▎   | 20/32 [06:24<03:34, 17.90s/it] 66%|██████▌   | 21/32 [06:24<03:17, 18.00s/it]                                                66%|██████▌   | 21/32 [06:42<03:17, 18.00s/it] 69%|██████▉   | 22/32 [06:42<02:59, 17.96s/it]                                                69%|██████▉   | 22/32 [06:59<02:59, 17.96s/it] 72%|███████▏  | 23/32 [06:59<02:40, 17.86s/it]                                                72%|███████▏  | 23/32 [07:17<02:40, 17.86s/it] 75%|███████▌  | 24/32 [07:17<02:23, 17.99s/it]                                                75%|███████▌  | 24/32 [07:35<02:23, 17.99s/it] 78%|███████▊  | 25/32 [07:35<02:05, 17.96s/it]                                                78%|███████▊  | 25/32 [07:53<02:05, 17.96s/it] 81%|████████▏ | 26/32 [07:53<01:47, 17.91s/it]                                                81%|████████▏ | 26/32 [08:11<01:47, 17.91s/it] 84%|████████▍ | 27/32 [08:11<01:29, 17.93s/it]                                                84%|████████▍ | 27/32 [08:29<01:29, 17.93s/it] 88%|████████▊ | 28/32 [08:29<01:11, 17.97s/it]                                                88%|████████▊ | 28/32 [08:47<01:11, 17.97s/it] 91%|█████████ | 29/32 [08:47<00:53, 17.98s/it]                                                91%|█████████ | 29/32 [09:05<00:53, 17.98s/it] 94%|█████████▍| 30/32 [09:05<00:35, 17.99s/it]                                                94%|█████████▍| 30/32 [09:23<00:35, 17.99s/it] 97%|█████████▋| 31/32 [09:23<00:17, 17.97s/it]W1211 07:20:08.558030 140027750851712 torch/distributed/elastic/agent/server/api.py:688] Received Signals.SIGTERM death signal, shutting down workers
W1211 07:20:08.558453 140027750851712 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 311382 closing signal SIGTERM
W1211 07:20:08.558867 140027750851712 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 311383 closing signal SIGTERM
W1211 07:20:08.559699 140027750851712 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 311384 closing signal SIGTERM
W1211 07:20:08.559998 140027750851712 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 311385 closing signal SIGTERM
Traceback (most recent call last):
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1165, in launch_command
    multi_gpu_launcher(args)
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/accelerate/commands/launch.py", line 799, in multi_gpu_launcher
    distrib_run.run(args)
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 255, in launch_agent
    result = agent.run()
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    result = f(*args, **kwargs)
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 680, in run
    result = self._invoke_run(role)
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 835, in _invoke_run
    time.sleep(monitor_interval)
  File "/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 79, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 311318 got signal: 15

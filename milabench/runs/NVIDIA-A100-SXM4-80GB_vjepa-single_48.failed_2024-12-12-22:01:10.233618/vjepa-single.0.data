{"event": "config", "data": {"system": {"arch": "cuda", "sshkey": null, "nodes": [{"name": "local", "ip": "127.0.0.1", "sshport": 22, "user": "root", "main": true, "hostname": "cn-g017.server.mila.quebec", "local": true}], "self": {"name": "local", "ip": "127.0.0.1", "sshport": 22, "user": "root", "main": true, "hostname": "cn-g017.server.mila.quebec", "local": true}}, "dirs": {"base": "/network/scratch/o/ortizgas/data/milabench", "venv": "/network/scratch/o/ortizgas/data/milabench/venv/torch", "data": "/network/scratch/o/ortizgas/data/milabench/data", "runs": "/network/scratch/o/ortizgas/data/milabench/runs", "extra": "/network/scratch/o/ortizgas/data/milabench/extra/vjepa-single", "cache": "/network/scratch/o/ortizgas/data/milabench/cache"}, "group": "vjepa-single", "install_group": "torch", "install_variant": "cuda", "run_name": "NVIDIA-A100-SXM4-80GB_vjepa-single_48.staging", "enabled": true, "capabilities": {"nodes": 1}, "max_duration": 600, "voir": {"options": {"stop": 60, "interval": "1s"}}, "validation": {"usage": {"gpu_load_threshold": 0.5, "gpu_mem_threshold": 0.5}}, "config_base": "/home/mila/o/ortizgas/CODE/milabench/config", "config_file": "/home/mila/o/ortizgas/CODE/milabench/config/standard.yaml", "definition": "/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa", "tags": ["monogpu", "video"], "argv": {"--batch_size": 24, "--num_workers": "auto({n_worker}, 12)", "--dataset": "{milabench_data}/FakeVideo/video_metainfo.csv", "--output": "{milabench_extra}"}, "plan": {"method": "njobs", "n": 1}, "weight": 1.0, "name": "vjepa-single", "tag": ["vjepa-single", "0"], "job-number": 0, "devices": [0]}, "pipe": null}
{"event": "meta", "data": {"cpu": {"count": 64, "brand": "AMD EPYC 7543 32-Core Processor"}, "os": {"sysname": "Linux", "nodename": "cn-g017.server.mila.quebec", "release": "5.15.0-101-generic", "version": "#111-Ubuntu SMP Tue Mar 5 20:16:58 UTC 2024", "machine": "x86_64"}, "accelerators": {"arch": "cuda", "gpus": {"0": {"minor_number": "0", "device": 0, "product": "NVIDIA A100-SXM4-80GB", "memory": {"used": 578.375, "total": 81920.0}, "utilization": {"compute": 0.0, "memory": 0}, "temperature": 27.0, "power": 58.625, "selection_variable": "CUDA_VISIBLE_DEVICES"}}}, "date": 1734076606.817142, "milabench": {"tag": "v1.0.0_RC1-13-g7a90b16", "commit": "7a90b1691650232ecd63abded0b7be84bb294c05", "date": "2024-11-08 11:28:56 -0500"}, "pytorch": {"torch": "2.4.0+cu121", "compiler": "GCC 9.3", "cpp": "C++ Version: 201703", "intel": "Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications", "mkl": "OpenMP 201511 (a.k.a. OpenMP 4.5)", "openmp": "OpenMP 201511 (a.k.a. OpenMP 4.5)", "lapack": "LAPACK is enabled (usually provided by MKL)", "nnpack": "NNPACK is enabled", "cpu": "CPU capability usage: AVX2", "build_settings": {"BLAS_INFO": "mkl", "BUILD_TYPE": "Release", "CUDA_VERSION": "12.1", "CUDNN_VERSION": "9.1.0", "CXX_COMPILER": "/opt/rh/devtoolset-9/root/usr/bin/c++", "CXX_FLAGS": "-D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow", "LAPACK_INFO": "mkl", "PERF_WITH_AVX": "1", "PERF_WITH_AVX2": "1", "PERF_WITH_AVX512": "1", "TORCH_VERSION": "2.4.0", "USE_CUDA": "ON", "USE_CUDNN": "ON", "USE_CUSPARSELT": "1", "USE_EXCEPTION_PTR": "1", "USE_GFLAGS": "OFF", "USE_GLOG": "OFF", "USE_GLOO": "ON", "USE_MKL": "ON", "USE_MKLDNN": "ON", "USE_MPI": "OFF", "USE_NCCL": "1", "USE_NNPACK": "ON", "USE_OPENMP": "ON", "USE_ROCM": "OFF", "USE_ROCM_KERNEL_ASSERT": "OFF"}}}, "pipe": null}
{"event": "start", "data": {"command": ["/network/scratch/o/ortizgas/data/milabench/venv/torch/bin/voir", "--config", "/network/scratch/o/ortizgas/data/milabench/extra/vjepa-single/voirconf-vjepa-single.0-0efae956f1553a76c1e03985181900f5.json", "/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py", "--batch_size", "48", "--num_workers", "12", "--dataset", "/network/scratch/o/ortizgas/data/milabench/data/FakeVideo/video_metainfo.csv", "--output", "/network/scratch/o/ortizgas/data/milabench/extra/vjepa-single"], "time": 1734058606.8944488}, "pipe": null}
{"event": "phase", "data": {"name": "init"}, "pipe": "data"}
{"event": "phase", "data": {"name": "parse_args"}, "pipe": "data"}
{"event": "phase", "data": {"name": "load_script"}, "pipe": "data"}
{"event": "phase", "data": {"name": "run_script"}, "pipe": "data"}
{"event": "line", "data": "INFO:__main__:loaded params...\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:which_dtype='bfloat16'\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:Initialized (rank/world-size) 0/1\n", "pipe": "stdout"}
{"event": "data", "data": {"task": "main", "time": 1734058623.5179503, "gpudata": {"0": {"memory": [582.375, 81920.0], "load": 0.0, "temperature": 26.0, "power": 58.382}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734058623.5179503, "process": {"pid": 3630119, "load": 0.0, "num": 33, "read_bytes": 303867064.0, "write_bytes": 4186.0, "read_chars": 35391881.0, "write_chars": 686.0, "memory": [3151126528.0, 1081778790400]}}, "pipe": "data"}
{"event": "line", "data": "INFO:root:MultiMaskWrapper(\n", "pipe": "stdout"}
{"event": "line", "data": "  (backbone): VisionTransformer(\n", "pipe": "stdout"}
{"event": "line", "data": "    (patch_embed): PatchEmbed3D(\n", "pipe": "stdout"}
{"event": "line", "data": "      (proj): Conv3d(3, 1280, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n", "pipe": "stdout"}
{"event": "line", "data": "    )\n", "pipe": "stdout"}
{"event": "line", "data": "    (blocks): ModuleList(\n", "pipe": "stdout"}
{"event": "line", "data": "      (0-31): 32 x Block(\n", "pipe": "stdout"}
{"event": "line", "data": "        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n", "pipe": "stdout"}
{"event": "line", "data": "        (attn): Attention(\n", "pipe": "stdout"}
{"event": "line", "data": "          (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (attn_drop): Dropout(p=0.0, inplace=False)\n", "pipe": "stdout"}
{"event": "line", "data": "          (proj): Linear(in_features=1280, out_features=1280, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (proj_drop): Dropout(p=0.0, inplace=False)\n", "pipe": "stdout"}
{"event": "line", "data": "        )\n", "pipe": "stdout"}
{"event": "line", "data": "        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n", "pipe": "stdout"}
{"event": "line", "data": "        (mlp): MLP(\n", "pipe": "stdout"}
{"event": "line", "data": "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (act): GELU(approximate='none')\n", "pipe": "stdout"}
{"event": "line", "data": "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (drop): Dropout(p=0.0, inplace=False)\n", "pipe": "stdout"}
{"event": "line", "data": "        )\n", "pipe": "stdout"}
{"event": "line", "data": "      )\n", "pipe": "stdout"}
{"event": "line", "data": "    )\n", "pipe": "stdout"}
{"event": "line", "data": "    (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n", "pipe": "stdout"}
{"event": "line", "data": "  )\n", "pipe": "stdout"}
{"event": "line", "data": ")\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:root:PredictorMultiMaskWrapper(\n", "pipe": "stdout"}
{"event": "line", "data": "  (backbone): VisionTransformerPredictor(\n", "pipe": "stdout"}
{"event": "line", "data": "    (predictor_embed): Linear(in_features=1280, out_features=384, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "    (mask_tokens): ParameterList(\n", "pipe": "stdout"}
{"event": "line", "data": "        (0): Parameter containing: [torch.float32 of size 1x1x384 (cuda:0)]\n", "pipe": "stdout"}
{"event": "line", "data": "        (1): Parameter containing: [torch.float32 of size 1x1x384 (cuda:0)]\n", "pipe": "stdout"}
{"event": "line", "data": "    )\n", "pipe": "stdout"}
{"event": "line", "data": "    (predictor_blocks): ModuleList(\n", "pipe": "stdout"}
{"event": "line", "data": "      (0-11): 12 x Block(\n", "pipe": "stdout"}
{"event": "line", "data": "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n", "pipe": "stdout"}
{"event": "line", "data": "        (attn): Attention(\n", "pipe": "stdout"}
{"event": "line", "data": "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (attn_drop): Dropout(p=0.0, inplace=False)\n", "pipe": "stdout"}
{"event": "line", "data": "          (proj): Linear(in_features=384, out_features=384, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (proj_drop): Dropout(p=0.0, inplace=False)\n", "pipe": "stdout"}
{"event": "line", "data": "        )\n", "pipe": "stdout"}
{"event": "line", "data": "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n", "pipe": "stdout"}
{"event": "line", "data": "        (mlp): MLP(\n", "pipe": "stdout"}
{"event": "line", "data": "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (act): GELU(approximate='none')\n", "pipe": "stdout"}
{"event": "line", "data": "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "          (drop): Dropout(p=0.0, inplace=False)\n", "pipe": "stdout"}
{"event": "line", "data": "        )\n", "pipe": "stdout"}
{"event": "line", "data": "      )\n", "pipe": "stdout"}
{"event": "line", "data": "    )\n", "pipe": "stdout"}
{"event": "line", "data": "    (predictor_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n", "pipe": "stdout"}
{"event": "line", "data": "    (predictor_proj): Linear(in_features=384, out_features=1280, bias=True)\n", "pipe": "stdout"}
{"event": "line", "data": "  )\n", "pipe": "stdout"}
{"event": "line", "data": ")\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:root:Encoder number of parameters: 631648000\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:root:Predictor number of parameters: 22279808\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:Initializing basic multi-block mask\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:root:VideoDataset dataset created\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:root:VideoDataset unsupervised data loader created\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:iterations per epoch/dataest length: 300/20\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:root:Using AdamW\n", "pipe": "stdout"}
{"event": "line", "data": "/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/jepa/app/vjepa/utils.py:209: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n", "pipe": "stderr"}
{"event": "line", "data": "  scaler = torch.cuda.amp.GradScaler() if mixed_precision else None\n", "pipe": "stderr"}
{"event": "line", "data": "INFO:__main__:Initializing loader...\n", "pipe": "stdout"}
{"event": "data", "data": {"progress": [0, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734058634.5610085, "gpudata": {"0": {"memory": [6180.25, 81920.0], "load": 0.0, "temperature": 27.0, "power": 74.137}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734058634.5610085, "process": {"pid": 3630119, "load": 1.359375, "num": 34, "read_bytes": 1077295916.0, "write_bytes": 12378.0, "read_chars": 119384621.0, "write_chars": 82604.0, "memory": [1329733632.0, 1081778790400]}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734058648.595239, "gpudata": {"0": {"memory": [6180.25, 81920.0], "load": 0.0, "temperature": 27.0, "power": 74.137}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734058648.595239, "process": {"pid": 3630119, "load": 0.015625, "num": 35, "read_bytes": 2170808601.0, "write_bytes": 24666.0, "read_chars": 240152707.0, "write_chars": 314330.0, "memory": [2231402496.0, 1081778790400]}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734058665.633503, "gpudata": {"0": {"memory": [6180.25, 81920.0], "load": 0.0, "temperature": 27.0, "power": 74.137}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734058665.633503, "process": {"pid": 3630119, "load": 0.0, "num": 35, "read_bytes": 3247154066.0, "write_bytes": 36954.0, "read_chars": 358691891.0, "write_chars": 546054.0, "memory": [3118043136.0, 1081778790400]}}, "pipe": "data"}
{"event": "line", "data": "INFO:__main__:Epoch 1\n", "pipe": "stdout"}
{"event": "line", "data": "/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py:463: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n", "pipe": "stderr"}
{"event": "line", "data": "  with acc.amp.autocast(dtype=dtype, enabled=mixed_precision):\n", "pipe": "stderr"}
{"event": "data", "data": {"task": "main", "time": 1734058685.679237, "gpudata": {"0": {"memory": [6180.25, 81920.0], "load": 0.0, "temperature": 27.0, "power": 74.137}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734058685.679237, "process": {"pid": 3630119, "load": 9.3953125, "num": 41, "read_bytes": 16003415194.0, "write_bytes": 53338.0, "read_chars": 11832531259.0, "write_chars": 777806.0, "memory": [8054530048.0, 1081778790400]}}, "pipe": "data"}
{"event": "line", "data": "/home/mila/o/ortizgas/env/cp310/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n", "pipe": "stderr"}
{"event": "line", "data": "  self.gen = func(*args, **kwds)\n", "pipe": "stderr"}
{"event": "line", "data": "INFO:__main__:[1,     0] loss: 0.849 | p0.849 r0.836 | input_var: 0.359 0.273 | masks: [320.0, 48.0] [wd: 4.00e-02] [lr: 2.00e-04] [mem: 5.36e+04] [gpu: 5089.5 ms][wall: 13278.1 ms]\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,     0] first moment: 4.68e-06 [9.02e-08 6.70e-05] second moment: 2.44e-11 [5.82e-15 7.34e-10]\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,     0] enc_grad_stats: f/l[2.45e-02 5.35e-03] mn/mx(5.35e-03, 2.74e-02) 0.00e+00\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,     0] pred_grad_stats: f/l[9.71e-02 6.10e-02] mn/mx(8.01e-03, 3.79e-01) 0.00e+00\n", "pipe": "stdout"}
{"event": "data", "data": {"progress": [1, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [2, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [3, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [4, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [5, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [6, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [7, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [8, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [9, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [10, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "line", "data": "INFO:__main__:[1,    10] loss: 0.610 | p0.610 r0.947 | input_var: 0.360 0.318 | masks: [346.9, 81.5] [wd: 4.00e-02] [lr: 2.00e-04] [mem: 7.07e+04] [gpu: 2166.9 ms][wall: 2937.5 ms]\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,    10] first moment: 3.57e-06 [3.25e-08 2.52e-04] second moment: 4.39e-11 [5.85e-15 2.94e-09]\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,    10] enc_grad_stats: f/l[3.99e-05 2.66e-05] mn/mx(2.45e-05, 7.19e-05) 0.00e+00\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,    10] pred_grad_stats: f/l[4.10e-03 4.36e-03] mn/mx(3.32e-04, 3.45e-01) 0.00e+00\n", "pipe": "stdout"}
{"event": "data", "data": {"progress": [11, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734058709.7300296, "gpudata": {"0": {"memory": [75936.25, 81920.0], "load": 1.0, "temperature": 47.0, "power": 344.51}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734058709.7300296, "process": {"pid": 3630119, "load": 0.0, "num": 35, "read_bytes": 51670764114.0, "write_bytes": 53501.0, "read_chars": 47358891944.0, "write_chars": 975599.0, "memory": [24955555840.0, 1081778790400]}}, "pipe": "data"}
{"event": "data", "data": {"progress": [12, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [13, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [14, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [15, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [16, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [17, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [18, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [19, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [20, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.8485513925552368, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.7352986335754395, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.6785407066345215, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.6422852277755737, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.6116654872894287, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.5842605829238892, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.5599181652069092, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.538751482963562, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.5195415019989014, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.5030498504638672, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.4879995584487915, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.47459545731544495, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.460786908864975, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.44635340571403503, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.4324098229408264, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.41746985912323, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.4029496908187866, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.38720232248306274, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.3721884489059448, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.3564513921737671, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 3.574794123146683, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 25.51165427068282, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 25.937499896933634, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 29.2631500767159, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 25.236628693033293, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 18.1885025587758, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 27.537692608937537, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 28.765332717669065, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 26.11818062258639, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 24.52915544538817, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 24.69884898750774, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 24.986217471899273, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 24.518710500496184, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 25.318889447429996, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 24.778955129356383, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 24.773154049861567, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 24.18864455784102, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 24.817907903935883, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 25.785463964050805, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 24.145090121934498, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "line", "data": "INFO:__main__:Exhausted data loaders after 20. Refreshing...\n", "pipe": "stdout"}
{"event": "data", "data": {"progress": [20, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734058733.781728, "gpudata": {"0": {"memory": [79156.25, 81920.0], "load": 1.0, "temperature": 56.0, "power": 455.483}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734058733.781728, "process": {"pid": 3630119, "load": 7.9921875, "num": 35, "read_bytes": 58549233243.0, "write_bytes": 54209.0, "read_chars": 54237777987.0, "write_chars": 979363.0, "memory": [25260716032.0, 1081778790400]}}, "pipe": "data"}
{"event": "line", "data": "INFO:__main__:[1,    20] loss: 0.514 | p0.514 r0.962 | input_var: 0.360 0.320 | masks: [352.8, 97.5] [wd: 4.00e-02] [lr: 2.01e-04] [mem: 7.08e+04] [gpu: 2041.6 ms][wall: 2866.3 ms]\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,    20] first moment: 2.85e-06 [1.16e-08 2.77e-04] second moment: 5.84e-11 [5.79e-15 5.24e-09]\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,    20] enc_grad_stats: f/l[4.30e-05 1.66e-05] mn/mx(1.63e-05, 7.77e-05) 0.00e+00\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,    20] pred_grad_stats: f/l[2.43e-03 2.71e-03] mn/mx(2.07e-04, 3.23e-01) 0.00e+00\n", "pipe": "stdout"}
{"event": "data", "data": {"progress": [21, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [22, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [23, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [24, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [25, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [26, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [27, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [28, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [29, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [30, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "line", "data": "INFO:__main__:[1,    30] loss: 0.433 | p0.433 r0.968 | input_var: 0.360 0.319 | masks: [351.5, 99.1] [wd: 4.00e-02] [lr: 2.01e-04] [mem: 7.10e+04] [gpu: 1970.5 ms][wall: 2536.4 ms]\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,    30] first moment: 2.13e-06 [4.22e-09 2.46e-04] second moment: 6.78e-11 [5.73e-15 6.75e-09]\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,    30] enc_grad_stats: f/l[8.29e-05 1.85e-05] mn/mx(1.73e-05, 1.50e-04) 0.00e+00\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,    30] pred_grad_stats: f/l[1.74e-03 1.98e-03] mn/mx(1.47e-04, 2.38e-01) 0.00e+00\n", "pipe": "stdout"}
{"event": "data", "data": {"progress": [31, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734058757.8634346, "gpudata": {"0": {"memory": [80276.25, 81920.0], "load": 1.0, "temperature": 56.0, "power": 449.277}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734058757.8634346, "process": {"pid": 3630119, "load": 0.0, "num": 35, "read_bytes": 96680021047.0, "write_bytes": 54650.0, "read_chars": 92353646632.0, "write_chars": 1030086.0, "memory": [26184138752.0, 1081778790400]}}, "pipe": "data"}
{"event": "data", "data": {"progress": [32, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [33, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [34, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [35, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [36, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [37, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [38, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [39, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [40, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.34114110469818115, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.32583436369895935, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.31017005443573, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.2954472303390503, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.2808832824230194, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.2666693329811096, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.2537166476249695, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.24134039878845215, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.2297549843788147, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.21896988153457642, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.20863857865333557, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.19944533705711365, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.19066955149173737, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.1825856864452362, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.17498353123664856, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.16823051869869232, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.16220492124557495, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.15620502829551697, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.1507214903831482, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"loss": 0.14678911864757538, "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 4.787309422434377, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 26.777719310778267, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 24.51036430817824, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 24.88926090448021, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 28.048020651405178, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 25.837267190693286, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 27.9125433098869, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 24.5773425373361, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 28.294046360340673, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 25.476917957425215, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 24.45765551935572, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 25.93685148142075, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 29.108557101195867, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 26.731299575722467, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 28.189806315521427, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 28.27990181260897, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 26.861605309090923, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 24.486936420936477, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 25.722878660266737, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "data", "data": {"rate": 27.505727911707687, "units": "items/s", "task": "train"}, "pipe": "data"}
{"event": "line", "data": "INFO:__main__:Exhausted data loaders after 19. Refreshing...\n", "pipe": "stdout"}
{"event": "data", "data": {"progress": [40, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734058781.9093108, "gpudata": {"0": {"memory": [80278.25, 81920.0], "load": 1.0, "temperature": 57.0, "power": 342.214}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "time": 1734058781.9093108, "process": {"pid": 3630119, "load": 7.6640625, "num": 35, "read_bytes": 111211183765.0, "write_bytes": 55365.0, "read_chars": 106885229783.0, "write_chars": 1039271.0, "memory": [25231400960.0, 1081778790400]}}, "pipe": "data"}
{"event": "line", "data": "INFO:__main__:[1,    40] loss: 0.368 | p0.368 r0.971 | input_var: 0.360 0.320 | masks: [342.8, 97.2] [wd: 4.00e-02] [lr: 2.01e-04] [mem: 7.12e+04] [gpu: 1922.2 ms][wall: 2550.3 ms]\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,    40] first moment: 1.14e-06 [1.67e-09 1.22e-04] second moment: 7.05e-11 [5.68e-15 7.42e-09]\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,    40] enc_grad_stats: f/l[1.39e-04 3.54e-05] mn/mx(3.23e-05, 2.49e-04) 0.00e+00\n", "pipe": "stdout"}
{"event": "line", "data": "INFO:__main__:[1,    40] pred_grad_stats: f/l[3.56e-03 2.35e-03] mn/mx(2.78e-04, 1.56e-01) 0.00e+00\n", "pipe": "stdout"}
{"event": "data", "data": {"progress": [41, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [42, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [43, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [44, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [45, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "data", "data": {"progress": [46, 65], "task": "early_stop"}, "pipe": "data"}
{"event": "error", "data": {"type": "OutOfMemoryError", "message": "CUDA out of memory. Tried to allocate 248.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.75 MiB is free. Including non-PyTorch memory, this process has 79.40 GiB memory in use. Of the allocated memory 73.76 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [582.375, 81920.0], "load": 0.0, "temperature": 26.0, "power": 58.382}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [582.375, 81920.0], "load": 0.0, "temperature": 26.0, "power": 58.382}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [1140.25, 81920.0], "load": 0.0, "temperature": 26.0, "power": 74.379}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [6180.25, 81920.0], "load": 0.0, "temperature": 27.0, "power": 74.137}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [6180.25, 81920.0], "load": 0.0, "temperature": 27.0, "power": 74.137}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [6180.25, 81920.0], "load": 0.0, "temperature": 27.0, "power": 74.137}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [6180.25, 81920.0], "load": 0.0, "temperature": 27.0, "power": 74.137}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [6180.25, 81920.0], "load": 0.0, "temperature": 27.0, "power": 74.137}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [6180.25, 81920.0], "load": 0.0, "temperature": 27.0, "power": 74.137}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [6180.25, 81920.0], "load": 0.0, "temperature": 27.0, "power": 74.137}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [35166.25, 81920.0], "load": 0.25, "temperature": 34.0, "power": 86.863}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [78892.25, 81920.0], "load": 1.0, "temperature": 46.0, "power": 221.896}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [79950.25, 81920.0], "load": 1.0, "temperature": 56.0, "power": 409.85}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [80276.25, 81920.0], "load": 1.0, "temperature": 56.0, "power": 463.046}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [80278.25, 81920.0], "load": 1.0, "temperature": 59.0, "power": 421.732}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [80278.25, 81920.0], "load": 0.0, "temperature": 39.0, "power": 77.358}}}, "pipe": "data"}
{"event": "phase", "data": {"name": "finalize"}, "pipe": "data"}
{"event": "line", "data": "[rank0]: Traceback (most recent call last):\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/bin/voir\", line 8, in <module>\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     sys.exit(main())\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/cli.py\", line 128, in main\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     ov(sys.argv[1:] if argv is None else argv)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/phase.py\", line 331, in __call__\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     self._run(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/overseer.py\", line 242, in _run\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     set_value(func())\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/scriptutils.py\", line 37, in <lambda>\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     return lambda: exec(mainsection, glb, glb)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py\", line 656, in <module>\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     main()\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py\", line 645, in main\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     _main(params)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py\", line 509, in _main\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     (loss, loss_jepa, loss_reg, _new_lr, _new_wd, grad_stats, grad_stats_pred, optim_stats,), gpu_etime_ms = gpu_timer(train_step)\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/jepa/src/utils/logging.py\", line 24, in gpu_timer\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     result = closure()\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py\", line 474, in train_step\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     scaler.scale(loss).backward()\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/_tensor.py\", line 521, in backward\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     torch.autograd.backward(\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 289, in backward\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     _engine_run_backward(\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:   File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/torch/autograd/graph.py\", line 768, in _engine_run_backward\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n", "pipe": "stderr"}
{"event": "line", "data": "[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 248.00 MiB. GPU 0 has a total capacity of 79.44 GiB of which 7.75 MiB is free. Including non-PyTorch memory, this process has 79.40 GiB memory in use. Of the allocated memory 73.76 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n", "pipe": "stderr"}
{"event": "end", "data": {"command": ["/network/scratch/o/ortizgas/data/milabench/venv/torch/bin/voir", "--config", "/network/scratch/o/ortizgas/data/milabench/extra/vjepa-single/voirconf-vjepa-single.0-0efae956f1553a76c1e03985181900f5.json", "/home/mila/o/ortizgas/CODE/milabench/benchmarks/vjepa/main.py", "--batch_size", "48", "--num_workers", "12", "--dataset", "/network/scratch/o/ortizgas/data/milabench/data/FakeVideo/video_metainfo.csv", "--output", "/network/scratch/o/ortizgas/data/milabench/extra/vjepa-single"], "time": 1734058869.7469733, "return_code": 1}, "pipe": null}

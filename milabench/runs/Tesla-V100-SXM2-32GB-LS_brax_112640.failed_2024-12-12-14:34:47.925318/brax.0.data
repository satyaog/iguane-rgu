{"event": "config", "data": {"system": {"arch": "cuda", "sshkey": null, "nodes": [{"name": "local", "ip": "127.0.0.1", "sshport": 22, "user": "root", "main": true, "hostname": "cn-e002.server.mila.quebec", "local": true}], "self": {"name": "local", "ip": "127.0.0.1", "sshport": 22, "user": "root", "main": true, "hostname": "cn-e002.server.mila.quebec", "local": true}}, "dirs": {"base": "/network/scratch/o/ortizgas/data/milabench", "venv": "/network/scratch/o/ortizgas/data/milabench/venv/torch", "data": "/network/scratch/o/ortizgas/data/milabench/data", "runs": "/network/scratch/o/ortizgas/data/milabench/runs", "extra": "/network/scratch/o/ortizgas/data/milabench/extra/brax", "cache": "/network/scratch/o/ortizgas/data/milabench/cache"}, "group": "brax", "install_group": "torch", "install_variant": "cuda", "run_name": "Tesla-V100-SXM2-32GB-LS_brax_112640.staging", "enabled": true, "capabilities": {"nodes": 1}, "max_duration": 600, "voir": {"options": {"stop": 60, "interval": "1s"}}, "validation": {"usage": {"gpu_load_threshold": 0.5, "gpu_mem_threshold": 0.5}}, "config_base": "/home/mila/o/ortizgas/CODE/milabench/config", "config_file": "/home/mila/o/ortizgas/CODE/milabench/config/standard.yaml", "tags": ["gym", "jax", "multigpu", "nobatch", "rl"], "definition": "/home/mila/o/ortizgas/CODE/milabench/benchmarks/brax", "plan": {"method": "njobs", "n": 1}, "argv": {"--episode-length": 20, "--batch-size": 1024, "--num-minibatches": 32, "--num-envs": 8192}, "weight": 1.0, "name": "brax", "tag": ["brax", "0"], "job-number": 0, "devices": [0]}, "pipe": null}
{"event": "meta", "data": {"cpu": {"count": 40, "brand": "Intel(R) Xeon(R) CPU E5-2698 v4 @ 2.20GHz"}, "os": {"sysname": "Linux", "nodename": "cn-e002.server.mila.quebec", "release": "5.15.0-1048-nvidia", "version": "#48-Ubuntu SMP Thu Mar 21 18:19:02 UTC 2024", "machine": "x86_64"}, "accelerators": {"arch": "cuda", "gpus": {"0": {"minor_number": "0", "device": 0, "product": "Tesla V100-SXM2-32GB-LS", "memory": {"used": 267.0, "total": 32768.0}, "utilization": {"compute": 0.0, "memory": 0}, "temperature": 41.0, "power": 46.416, "selection_variable": "CUDA_VISIBLE_DEVICES"}}}, "date": 1734050013.726066, "milabench": {"tag": "v1.0.0_RC1-13-g7a90b16", "commit": "7a90b1691650232ecd63abded0b7be84bb294c05", "date": "2024-11-08 11:28:56 -0500"}, "pytorch": {"torch": "2.4.0+cu121", "compiler": "GCC 9.3", "cpp": "C++ Version: 201703", "intel": "Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications", "mkl": "OpenMP 201511 (a.k.a. OpenMP 4.5)", "openmp": "OpenMP 201511 (a.k.a. OpenMP 4.5)", "lapack": "LAPACK is enabled (usually provided by MKL)", "nnpack": "NNPACK is enabled", "cpu": "CPU capability usage: AVX2", "build_settings": {"BLAS_INFO": "mkl", "BUILD_TYPE": "Release", "CUDA_VERSION": "12.1", "CUDNN_VERSION": "9.1.0", "CXX_COMPILER": "/opt/rh/devtoolset-9/root/usr/bin/c++", "CXX_FLAGS": "-D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow", "LAPACK_INFO": "mkl", "PERF_WITH_AVX": "1", "PERF_WITH_AVX2": "1", "PERF_WITH_AVX512": "1", "TORCH_VERSION": "2.4.0", "USE_CUDA": "ON", "USE_CUDNN": "ON", "USE_CUSPARSELT": "1", "USE_EXCEPTION_PTR": "1", "USE_GFLAGS": "OFF", "USE_GLOG": "OFF", "USE_GLOO": "ON", "USE_MKL": "ON", "USE_MKLDNN": "ON", "USE_MPI": "OFF", "USE_NCCL": "1", "USE_NNPACK": "ON", "USE_OPENMP": "ON", "USE_ROCM": "OFF", "USE_ROCM_KERNEL_ASSERT": "OFF"}}}, "pipe": null}
{"event": "start", "data": {"command": ["/network/scratch/o/ortizgas/data/milabench/venv/torch/bin/voir", "--config", "/network/scratch/o/ortizgas/data/milabench/extra/brax/voirconf-brax.0-0efae956f1553a76c1e03985181900f5.json", "/home/mila/o/ortizgas/CODE/milabench/benchmarks/brax/main.py", "--episode-length", "20", "--batch-size", "112640", "--num-minibatches", "32", "--num-envs", "8192"], "time": 1734032013.8126726}, "pipe": null}
{"event": "phase", "data": {"name": "init"}, "pipe": "data"}
{"event": "phase", "data": {"name": "parse_args"}, "pipe": "data"}
{"event": "phase", "data": {"name": "load_script"}, "pipe": "data"}
{"event": "phase", "data": {"name": "run_script"}, "pipe": "data"}
{"event": "line", "data": "2024-12-12 14:33:45.682781: W external/xla/xla/service/gpu/nvptx_compiler.cc:893] The NVIDIA driver's CUDA version is 12.2 which is older than the PTX compiler version 12.6.77. Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n", "pipe": "stderr"}
{"event": "line", "data": "2024-12-12 14:33:55.142629: E external/xla/xla/service/hlo_lexer.cc:438] Failed to parse int literal: 894515288310727292233\n", "pipe": "stderr"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [584.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.756}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [584.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.722}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [586.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.722}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [724.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.722}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [770.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.722}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [770.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.756}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [770.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.722}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [898.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.722}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [898.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.722}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [898.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 49.791}}}, "pipe": "data"}
{"event": "data", "data": {"loss": 2.5312447547912598}, "pipe": "data"}
{"event": "line", "data": "2024-12-12 14:34:45.848656: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_0_bfc) ran out of memory trying to allocate 19.38GiB (rounded to 20810153984)requested by op \n", "pipe": "stderr"}
{"event": "line", "data": "2024-12-12 14:34:45.849103: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] ________________________________________________________________________________________**____******\n", "pipe": "stderr"}
{"event": "line", "data": "E1212 14:34:45.849178  899274 pjrt_stream_executor_client.cc:3067] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 20810153816 bytes.\n", "pipe": "stderr"}
{"event": "error", "data": {"type": "XlaRuntimeError", "message": "RESOURCE_EXHAUSTED: Out of memory while trying to allocate 20810153816 bytes."}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [916.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.722}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [916.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.722}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [916.625, 32768.0], "load": 0.0, "temperature": 34.0, "power": 50.722}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [5268.625, 32768.0], "load": 1.0, "temperature": 36.0, "power": 83.919}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [5268.625, 32768.0], "load": 0.99, "temperature": 37.0, "power": 164.28}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [5268.625, 32768.0], "load": 1.0, "temperature": 37.0, "power": 134.699}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [5268.625, 32768.0], "load": 0.0, "temperature": 36.0, "power": 71.879}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [5268.625, 32768.0], "load": 0.0, "temperature": 36.0, "power": 71.879}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [5268.625, 32768.0], "load": 0.0, "temperature": 36.0, "power": 71.879}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [5268.625, 32768.0], "load": 0.0, "temperature": 36.0, "power": 71.879}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [5268.625, 32768.0], "load": 0.0, "temperature": 36.0, "power": 71.879}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [5268.625, 32768.0], "load": 0.0, "temperature": 36.0, "power": 71.879}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [5268.625, 32768.0], "load": 0.0, "temperature": 36.0, "power": 71.879}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [5268.625, 32768.0], "load": 0.0, "temperature": 36.0, "power": 71.879}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [5268.625, 32768.0], "load": 0.0, "temperature": 36.0, "power": 71.879}}}, "pipe": "data"}
{"event": "line", "data": "jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.\n", "pipe": "stderr"}
{"event": "line", "data": "\n", "pipe": "stderr"}
{"event": "line", "data": "The above exception was the direct cause of the following exception:\n", "pipe": "stderr"}
{"event": "line", "data": "\n", "pipe": "stderr"}
{"event": "line", "data": "Traceback (most recent call last):\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/bin/voir\", line 8, in <module>\n", "pipe": "stderr"}
{"event": "phase", "data": {"name": "finalize"}, "pipe": "data"}
{"event": "line", "data": "    sys.exit(main())\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/cli.py\", line 128, in main\n", "pipe": "stderr"}
{"event": "line", "data": "    ov(sys.argv[1:] if argv is None else argv)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/phase.py\", line 331, in __call__\n", "pipe": "stderr"}
{"event": "line", "data": "    self._run(*args, **kwargs)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/overseer.py\", line 242, in _run\n", "pipe": "stderr"}
{"event": "line", "data": "    set_value(func())\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/voir/scriptutils.py\", line 37, in <lambda>\n", "pipe": "stderr"}
{"event": "line", "data": "    return lambda: exec(mainsection, glb, glb)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/brax/main.py\", line 123, in <module>\n", "pipe": "stderr"}
{"event": "line", "data": "    main()\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/brax/main.py\", line 112, in main\n", "pipe": "stderr"}
{"event": "line", "data": "    run()\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/home/mila/o/ortizgas/CODE/milabench/benchmarks/brax/main.py\", line 91, in run\n", "pipe": "stderr"}
{"event": "line", "data": "    train(\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/brax/training/agents/ppo/train.py\", line 452, in train\n", "pipe": "stderr"}
{"event": "line", "data": "    training_epoch_with_timing(training_state, env_state, epoch_keys)\n", "pipe": "stderr"}
{"event": "line", "data": "  File \"/network/scratch/o/ortizgas/data/milabench/venv/torch/lib/python3.10/site-packages/brax/training/agents/ppo/train.py\", line 354, in training_epoch_with_timing\n", "pipe": "stderr"}
{"event": "line", "data": "    result = training_epoch(training_state, env_state, key)\n", "pipe": "stderr"}
{"event": "line", "data": "jaxlib.xla_extension.XlaRuntimeError: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 20810153816 bytes.\n", "pipe": "stderr"}
{"event": "end", "data": {"command": ["/network/scratch/o/ortizgas/data/milabench/venv/torch/bin/voir", "--config", "/network/scratch/o/ortizgas/data/milabench/extra/brax/voirconf-brax.0-0efae956f1553a76c1e03985181900f5.json", "/home/mila/o/ortizgas/CODE/milabench/benchmarks/brax/main.py", "--episode-length", "20", "--batch-size", "112640", "--num-minibatches", "32", "--num-envs", "8192"], "time": 1734032087.4684656, "return_code": 1}, "pipe": null}
